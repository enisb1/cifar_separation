{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Separazione di immagini Cifar10"
      ],
      "metadata": {
        "id": "mE7oyG0wv6e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparazione dei dati"
      ],
      "metadata": {
        "id": "USdmzjiO0W6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "iHjnh5XP0Sq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
        "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
        "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
        "assert cifar10_y_train.shape == (50000, 1)\n",
        "assert cifar10_y_test.shape == (10000, 1)\n",
        "\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
        "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
      ],
      "metadata": {
        "id": "yRYiW2ipukZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separiamo le immagini in due gruppi, in relazione alla loro etichetta.\n"
      ],
      "metadata": {
        "id": "ZkiGnU4d0k4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cond_1 = cifar10_y_train[:,0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
        "\n",
        "cond_2 = cifar10_y_train[:,0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
        "\n",
        "cond_1_test = cifar10_y_test[:,0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:,0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
      ],
      "metadata": {
        "id": "Dpey42Vo07Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adesso possiamo definire il generatore. In input abbiamo due datasets (X1,X2), le etichette corrispondenti (Y1,Y2) e una batchsize.\n",
        "\n",
        "Il generatore resituisce x_data, y_data, dove\n",
        "\n",
        "*   x_data è una batch di immagini ottenute come media di campioni random in X1 and X2\n",
        "*   y_data è una coppia di batch di etichette relative alle immagini componenti, espresse in formato categorico"
      ],
      "metadata": {
        "id": "qmLYNuR-0s0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
        "  size1 = X1.shape[0]\n",
        "  size2 = X2.shape[0]\n",
        "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
        "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
        "\n",
        "  while True:\n",
        "    num1 = np.random.randint(0, size1, batchsize)\n",
        "    num2 = np.random.randint(0, size2, batchsize)\n",
        "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
        "    y_data = (Y1_cat[num1],Y2_cat[num2])\n",
        "\n",
        "    yield x_data, y_data"
      ],
      "metadata": {
        "id": "7Y5Zpv5fw2hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanziamo un generatore su Cifar10 con batchsize=1, e testiamone il comportamento."
      ],
      "metadata": {
        "id": "Z9lf3TuP2pdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
      ],
      "metadata": {
        "id": "29TldJ6-720b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generiamo un esempio, mostriamo l'immagine che deve essere presa in input dal modello, e stampiamo le categorie delle due componenti sovrapposte.\n",
        "\n",
        "Potete rirpetere l'esecuzione della cella per mostrare nuovi esempi."
      ],
      "metadata": {
        "id": "W1DrJVzI3ysV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(datagen)\n",
        "\n",
        "print(\"first: {}, second = {}\".format(classes[np.argmax(y[0][0])],classes[np.argmax(y[1][0])+5]))\n",
        "#print(np.min(x[0]),np.max(x[0]))\n",
        "plt.imshow(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "qL1sMtjG8VmG",
        "outputId": "bda09af8-b3d0-4405-da18-c544e9156e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first: deer, second = horse\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7961dac40550>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modello (SAS) e Training**\n",
        "Ho chiamato il mio modello SAS (Shared and Separated), ispirandomi alla sua\n",
        "struttura.\n",
        "\n",
        "Il modello presenta una parte convolutiva iniziale in cui si ha Feature Extraction condivisa.\n",
        "In seguito si hanno dei blocchi convolutivi separati per lo specifico output, e poi si usa GAP e si combinano i risultati per passare ai layer densi.\n",
        "Anche nei layer densi si ha una parte condivisa, e poi una parte di layer densi separati per ciascun output finale.\n",
        "\n",
        "Accuratezza dell'80/81% per un numero di parametri abbastanza ridotto (1 milione).\n",
        "\n",
        "Questo modello è un buon mix tra eleganza, grandezza e accuratezza."
      ],
      "metadata": {
        "id": "f8bSMOow3EPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SAS_model():\n",
        "  input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "  # Shared feature extraction\n",
        "  x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  # Separated conv blocks for each output (extracting image-specific features)\n",
        "  x1 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x1 = layers.BatchNormalization()(x1)\n",
        "  x1 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x1)\n",
        "  x1 = layers.BatchNormalization()(x1)\n",
        "  x1 = layers.MaxPool2D(pool_size=(2, 2))(x1)\n",
        "  x1 = layers.Dropout(0.25)(x1)\n",
        "\n",
        "  x2 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
        "  x2 = layers.BatchNormalization()(x2)\n",
        "  x2 = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x2)\n",
        "  x2 = layers.BatchNormalization()(x2)\n",
        "  x2 = layers.MaxPool2D(pool_size=(2, 2))(x2)\n",
        "  x2 = layers.Dropout(0.25)(x2)\n",
        "\n",
        "  # GlobalAveragePooling instead of Flatten (tested and accuracy is around the same, with less parameters)\n",
        "  gap1 = layers.GlobalAveragePooling2D()(x1)\n",
        "  gap2 = layers.GlobalAveragePooling2D()(x2)\n",
        "\n",
        "  # Concatenate GAP outputs\n",
        "  combined = layers.Concatenate()([gap1, gap2])\n",
        "\n",
        "  # Shared Dense layer\n",
        "  shared_dense = layers.Dense(256, activation='relu')(combined)\n",
        "  shared_dense = layers.Dropout(0.25)(shared_dense)\n",
        "\n",
        "  # Two separate dense layers for predictions\n",
        "  output_1 = layers.Dense(128, activation='relu')(shared_dense)\n",
        "  output_1 = layers.Dropout(0.25)(output_1)\n",
        "  output_1 = layers.Dense(5, activation='softmax', name='output_1')(output_1)\n",
        "\n",
        "  output_2 = layers.Dense(128, activation='relu')(shared_dense)\n",
        "  output_2 = layers.Dropout(0.25)(output_2)\n",
        "  output_2 = layers.Dense(5, activation='softmax', name='output_2')(output_2)\n",
        "\n",
        "  model = Model(inputs=input_layer, outputs=[output_1, output_2])\n",
        "  return model"
      ],
      "metadata": {
        "id": "juiHgGtrix07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SAS_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ieBr0bYRUgPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59cc7ae0-b25d-4530-8566-10d1235a04db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m896\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m73,856\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_average_poolin… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m65,792\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m645\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m645\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_poolin… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,014,058\u001b[0m (3.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,014,058</span> (3.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,012,138\u001b[0m (3.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,012,138</span> (3.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},\n",
        "    metrics={'output_1': 'accuracy', 'output_2': 'accuracy'},\n",
        "    loss_weights={'output_1': 1.0, 'output_2': 1.0}\n",
        ")"
      ],
      "metadata": {
        "id": "xOLqJDxv4upq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "batch_size = 32\n",
        "train_gen = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batch_size)\n",
        "steps_per_epoch = math.ceil(cifar10_x_train_1.shape[0] / batch_size)"
      ],
      "metadata": {
        "id": "nME3w9o8cOpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=600,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW7dK7cr45gv",
        "outputId": "688ddef1-16c0-46a0-ea63-e49efaee7693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 3.0022 - output_1_accuracy: 0.3304 - output_1_loss: 1.5222 - output_2_accuracy: 0.3713 - output_2_loss: 1.4800\n",
            "Epoch 2/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.6049 - output_1_accuracy: 0.4276 - output_1_loss: 1.3474 - output_2_accuracy: 0.4948 - output_2_loss: 1.2575\n",
            "Epoch 3/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.4249 - output_1_accuracy: 0.4471 - output_1_loss: 1.3044 - output_2_accuracy: 0.5616 - output_2_loss: 1.1205\n",
            "Epoch 4/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.2856 - output_1_accuracy: 0.4818 - output_1_loss: 1.2480 - output_2_accuracy: 0.6043 - output_2_loss: 1.0376\n",
            "Epoch 5/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.1680 - output_1_accuracy: 0.5104 - output_1_loss: 1.1930 - output_2_accuracy: 0.6317 - output_2_loss: 0.9751\n",
            "Epoch 6/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.0923 - output_1_accuracy: 0.5330 - output_1_loss: 1.1485 - output_2_accuracy: 0.6460 - output_2_loss: 0.9438\n",
            "Epoch 7/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.0453 - output_1_accuracy: 0.5413 - output_1_loss: 1.1352 - output_2_accuracy: 0.6579 - output_2_loss: 0.9100\n",
            "Epoch 8/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.9812 - output_1_accuracy: 0.5626 - output_1_loss: 1.1040 - output_2_accuracy: 0.6728 - output_2_loss: 0.8772\n",
            "Epoch 9/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.9487 - output_1_accuracy: 0.5690 - output_1_loss: 1.0849 - output_2_accuracy: 0.6822 - output_2_loss: 0.8638\n",
            "Epoch 10/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.9243 - output_1_accuracy: 0.5713 - output_1_loss: 1.0821 - output_2_accuracy: 0.6916 - output_2_loss: 0.8422\n",
            "Epoch 11/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.8945 - output_1_accuracy: 0.5840 - output_1_loss: 1.0589 - output_2_accuracy: 0.6905 - output_2_loss: 0.8355\n",
            "Epoch 12/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.8552 - output_1_accuracy: 0.5870 - output_1_loss: 1.0492 - output_2_accuracy: 0.6992 - output_2_loss: 0.8060\n",
            "Epoch 13/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.8283 - output_1_accuracy: 0.5947 - output_1_loss: 1.0309 - output_2_accuracy: 0.7038 - output_2_loss: 0.7974\n",
            "Epoch 14/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.8264 - output_1_accuracy: 0.5965 - output_1_loss: 1.0306 - output_2_accuracy: 0.7060 - output_2_loss: 0.7958\n",
            "Epoch 15/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.7825 - output_1_accuracy: 0.6064 - output_1_loss: 1.0152 - output_2_accuracy: 0.7232 - output_2_loss: 0.7673\n",
            "Epoch 16/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.7831 - output_1_accuracy: 0.6109 - output_1_loss: 0.9990 - output_2_accuracy: 0.7165 - output_2_loss: 0.7841\n",
            "Epoch 17/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.7486 - output_1_accuracy: 0.6145 - output_1_loss: 0.9846 - output_2_accuracy: 0.7181 - output_2_loss: 0.7639\n",
            "Epoch 18/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.7530 - output_1_accuracy: 0.6154 - output_1_loss: 0.9884 - output_2_accuracy: 0.7232 - output_2_loss: 0.7646\n",
            "Epoch 19/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.7234 - output_1_accuracy: 0.6231 - output_1_loss: 0.9662 - output_2_accuracy: 0.7213 - output_2_loss: 0.7571\n",
            "Epoch 20/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.7129 - output_1_accuracy: 0.6245 - output_1_loss: 0.9668 - output_2_accuracy: 0.7281 - output_2_loss: 0.7462\n",
            "Epoch 21/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.6766 - output_1_accuracy: 0.6305 - output_1_loss: 0.9515 - output_2_accuracy: 0.7374 - output_2_loss: 0.7251\n",
            "Epoch 22/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.6750 - output_1_accuracy: 0.6380 - output_1_loss: 0.9421 - output_2_accuracy: 0.7313 - output_2_loss: 0.7328\n",
            "Epoch 23/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.6702 - output_1_accuracy: 0.6406 - output_1_loss: 0.9366 - output_2_accuracy: 0.7337 - output_2_loss: 0.7337\n",
            "Epoch 24/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.6468 - output_1_accuracy: 0.6337 - output_1_loss: 0.9339 - output_2_accuracy: 0.7437 - output_2_loss: 0.7128\n",
            "Epoch 25/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.6293 - output_1_accuracy: 0.6431 - output_1_loss: 0.9233 - output_2_accuracy: 0.7453 - output_2_loss: 0.7060\n",
            "Epoch 26/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.6429 - output_1_accuracy: 0.6322 - output_1_loss: 0.9524 - output_2_accuracy: 0.7463 - output_2_loss: 0.6905\n",
            "Epoch 27/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5989 - output_1_accuracy: 0.6396 - output_1_loss: 0.9227 - output_2_accuracy: 0.7552 - output_2_loss: 0.6761\n",
            "Epoch 28/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5927 - output_1_accuracy: 0.6526 - output_1_loss: 0.9010 - output_2_accuracy: 0.7474 - output_2_loss: 0.6916\n",
            "Epoch 29/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.6217 - output_1_accuracy: 0.6445 - output_1_loss: 0.9174 - output_2_accuracy: 0.7457 - output_2_loss: 0.7043\n",
            "Epoch 30/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5865 - output_1_accuracy: 0.6549 - output_1_loss: 0.9091 - output_2_accuracy: 0.7521 - output_2_loss: 0.6773\n",
            "Epoch 31/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5875 - output_1_accuracy: 0.6556 - output_1_loss: 0.9055 - output_2_accuracy: 0.7541 - output_2_loss: 0.6820\n",
            "Epoch 32/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5619 - output_1_accuracy: 0.6533 - output_1_loss: 0.8972 - output_2_accuracy: 0.7588 - output_2_loss: 0.6647\n",
            "Epoch 33/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5617 - output_1_accuracy: 0.6552 - output_1_loss: 0.9027 - output_2_accuracy: 0.7620 - output_2_loss: 0.6590\n",
            "Epoch 34/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5662 - output_1_accuracy: 0.6537 - output_1_loss: 0.8954 - output_2_accuracy: 0.7592 - output_2_loss: 0.6707\n",
            "Epoch 35/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5243 - output_1_accuracy: 0.6624 - output_1_loss: 0.8773 - output_2_accuracy: 0.7649 - output_2_loss: 0.6470\n",
            "Epoch 36/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5537 - output_1_accuracy: 0.6519 - output_1_loss: 0.8946 - output_2_accuracy: 0.7658 - output_2_loss: 0.6592\n",
            "Epoch 37/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5253 - output_1_accuracy: 0.6665 - output_1_loss: 0.8686 - output_2_accuracy: 0.7656 - output_2_loss: 0.6566\n",
            "Epoch 38/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5310 - output_1_accuracy: 0.6612 - output_1_loss: 0.8848 - output_2_accuracy: 0.7667 - output_2_loss: 0.6461\n",
            "Epoch 39/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5404 - output_1_accuracy: 0.6633 - output_1_loss: 0.8783 - output_2_accuracy: 0.7581 - output_2_loss: 0.6621\n",
            "Epoch 40/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5126 - output_1_accuracy: 0.6673 - output_1_loss: 0.8653 - output_2_accuracy: 0.7625 - output_2_loss: 0.6473\n",
            "Epoch 41/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.5068 - output_1_accuracy: 0.6697 - output_1_loss: 0.8705 - output_2_accuracy: 0.7689 - output_2_loss: 0.6363\n",
            "Epoch 42/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.5051 - output_1_accuracy: 0.6698 - output_1_loss: 0.8578 - output_2_accuracy: 0.7685 - output_2_loss: 0.6474\n",
            "Epoch 43/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4788 - output_1_accuracy: 0.6728 - output_1_loss: 0.8547 - output_2_accuracy: 0.7823 - output_2_loss: 0.6241\n",
            "Epoch 44/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.4831 - output_1_accuracy: 0.6673 - output_1_loss: 0.8531 - output_2_accuracy: 0.7753 - output_2_loss: 0.6300\n",
            "Epoch 45/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.4905 - output_1_accuracy: 0.6737 - output_1_loss: 0.8527 - output_2_accuracy: 0.7718 - output_2_loss: 0.6377\n",
            "Epoch 46/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4821 - output_1_accuracy: 0.6783 - output_1_loss: 0.8466 - output_2_accuracy: 0.7692 - output_2_loss: 0.6356\n",
            "Epoch 47/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.4815 - output_1_accuracy: 0.6749 - output_1_loss: 0.8537 - output_2_accuracy: 0.7769 - output_2_loss: 0.6278\n",
            "Epoch 48/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4703 - output_1_accuracy: 0.6809 - output_1_loss: 0.8399 - output_2_accuracy: 0.7703 - output_2_loss: 0.6304\n",
            "Epoch 49/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4568 - output_1_accuracy: 0.6810 - output_1_loss: 0.8332 - output_2_accuracy: 0.7736 - output_2_loss: 0.6235\n",
            "Epoch 50/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4750 - output_1_accuracy: 0.6761 - output_1_loss: 0.8486 - output_2_accuracy: 0.7740 - output_2_loss: 0.6264\n",
            "Epoch 51/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4627 - output_1_accuracy: 0.6772 - output_1_loss: 0.8444 - output_2_accuracy: 0.7768 - output_2_loss: 0.6184\n",
            "Epoch 52/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4528 - output_1_accuracy: 0.6864 - output_1_loss: 0.8365 - output_2_accuracy: 0.7718 - output_2_loss: 0.6162\n",
            "Epoch 53/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4234 - output_1_accuracy: 0.6898 - output_1_loss: 0.8197 - output_2_accuracy: 0.7806 - output_2_loss: 0.6037\n",
            "Epoch 54/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4447 - output_1_accuracy: 0.6866 - output_1_loss: 0.8308 - output_2_accuracy: 0.7841 - output_2_loss: 0.6139\n",
            "Epoch 55/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4303 - output_1_accuracy: 0.6879 - output_1_loss: 0.8237 - output_2_accuracy: 0.7790 - output_2_loss: 0.6066\n",
            "Epoch 56/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4399 - output_1_accuracy: 0.6868 - output_1_loss: 0.8250 - output_2_accuracy: 0.7832 - output_2_loss: 0.6149\n",
            "Epoch 57/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4086 - output_1_accuracy: 0.6923 - output_1_loss: 0.8060 - output_2_accuracy: 0.7831 - output_2_loss: 0.6026\n",
            "Epoch 58/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3896 - output_1_accuracy: 0.7002 - output_1_loss: 0.7973 - output_2_accuracy: 0.7855 - output_2_loss: 0.5923\n",
            "Epoch 59/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4265 - output_1_accuracy: 0.6863 - output_1_loss: 0.8282 - output_2_accuracy: 0.7889 - output_2_loss: 0.5983\n",
            "Epoch 60/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4256 - output_1_accuracy: 0.6843 - output_1_loss: 0.8198 - output_2_accuracy: 0.7813 - output_2_loss: 0.6058\n",
            "Epoch 61/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4157 - output_1_accuracy: 0.6855 - output_1_loss: 0.8183 - output_2_accuracy: 0.7827 - output_2_loss: 0.5974\n",
            "Epoch 62/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4050 - output_1_accuracy: 0.6899 - output_1_loss: 0.8104 - output_2_accuracy: 0.7846 - output_2_loss: 0.5946\n",
            "Epoch 63/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3900 - output_1_accuracy: 0.6981 - output_1_loss: 0.7981 - output_2_accuracy: 0.7883 - output_2_loss: 0.5919\n",
            "Epoch 64/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4183 - output_1_accuracy: 0.6909 - output_1_loss: 0.8159 - output_2_accuracy: 0.7810 - output_2_loss: 0.6024\n",
            "Epoch 65/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.4083 - output_1_accuracy: 0.6940 - output_1_loss: 0.8045 - output_2_accuracy: 0.7806 - output_2_loss: 0.6037\n",
            "Epoch 66/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3856 - output_1_accuracy: 0.6961 - output_1_loss: 0.7968 - output_2_accuracy: 0.7891 - output_2_loss: 0.5888\n",
            "Epoch 67/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3901 - output_1_accuracy: 0.6917 - output_1_loss: 0.8066 - output_2_accuracy: 0.7891 - output_2_loss: 0.5835\n",
            "Epoch 68/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3856 - output_1_accuracy: 0.6999 - output_1_loss: 0.8045 - output_2_accuracy: 0.7898 - output_2_loss: 0.5811\n",
            "Epoch 69/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3832 - output_1_accuracy: 0.6941 - output_1_loss: 0.8115 - output_2_accuracy: 0.7908 - output_2_loss: 0.5716\n",
            "Epoch 70/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3675 - output_1_accuracy: 0.7029 - output_1_loss: 0.7821 - output_2_accuracy: 0.7904 - output_2_loss: 0.5855\n",
            "Epoch 71/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3746 - output_1_accuracy: 0.6939 - output_1_loss: 0.7981 - output_2_accuracy: 0.7940 - output_2_loss: 0.5766\n",
            "Epoch 72/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3808 - output_1_accuracy: 0.7027 - output_1_loss: 0.7958 - output_2_accuracy: 0.7901 - output_2_loss: 0.5850\n",
            "Epoch 73/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3684 - output_1_accuracy: 0.6995 - output_1_loss: 0.7830 - output_2_accuracy: 0.7860 - output_2_loss: 0.5854\n",
            "Epoch 74/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3501 - output_1_accuracy: 0.7043 - output_1_loss: 0.7728 - output_2_accuracy: 0.7965 - output_2_loss: 0.5774\n",
            "Epoch 75/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3679 - output_1_accuracy: 0.6939 - output_1_loss: 0.7910 - output_2_accuracy: 0.7935 - output_2_loss: 0.5769\n",
            "Epoch 76/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3528 - output_1_accuracy: 0.7064 - output_1_loss: 0.7724 - output_2_accuracy: 0.7902 - output_2_loss: 0.5804\n",
            "Epoch 77/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.3498 - output_1_accuracy: 0.7068 - output_1_loss: 0.7721 - output_2_accuracy: 0.7918 - output_2_loss: 0.5777\n",
            "Epoch 78/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3525 - output_1_accuracy: 0.7030 - output_1_loss: 0.7818 - output_2_accuracy: 0.7959 - output_2_loss: 0.5707\n",
            "Epoch 79/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3556 - output_1_accuracy: 0.7070 - output_1_loss: 0.7729 - output_2_accuracy: 0.7958 - output_2_loss: 0.5827\n",
            "Epoch 80/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3634 - output_1_accuracy: 0.7025 - output_1_loss: 0.7833 - output_2_accuracy: 0.7931 - output_2_loss: 0.5801\n",
            "Epoch 81/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3561 - output_1_accuracy: 0.7005 - output_1_loss: 0.7845 - output_2_accuracy: 0.7948 - output_2_loss: 0.5715\n",
            "Epoch 82/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3514 - output_1_accuracy: 0.7027 - output_1_loss: 0.7814 - output_2_accuracy: 0.7956 - output_2_loss: 0.5700\n",
            "Epoch 83/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3409 - output_1_accuracy: 0.7011 - output_1_loss: 0.7883 - output_2_accuracy: 0.8024 - output_2_loss: 0.5526\n",
            "Epoch 84/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3372 - output_1_accuracy: 0.7094 - output_1_loss: 0.7717 - output_2_accuracy: 0.7957 - output_2_loss: 0.5656\n",
            "Epoch 85/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.3448 - output_1_accuracy: 0.7068 - output_1_loss: 0.7734 - output_2_accuracy: 0.7922 - output_2_loss: 0.5714\n",
            "Epoch 86/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3202 - output_1_accuracy: 0.7163 - output_1_loss: 0.7578 - output_2_accuracy: 0.7971 - output_2_loss: 0.5624\n",
            "Epoch 87/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3402 - output_1_accuracy: 0.7016 - output_1_loss: 0.7846 - output_2_accuracy: 0.7971 - output_2_loss: 0.5556\n",
            "Epoch 88/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3123 - output_1_accuracy: 0.7123 - output_1_loss: 0.7580 - output_2_accuracy: 0.8019 - output_2_loss: 0.5543\n",
            "Epoch 89/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3140 - output_1_accuracy: 0.7111 - output_1_loss: 0.7657 - output_2_accuracy: 0.8005 - output_2_loss: 0.5482\n",
            "Epoch 90/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3261 - output_1_accuracy: 0.7070 - output_1_loss: 0.7745 - output_2_accuracy: 0.8041 - output_2_loss: 0.5516\n",
            "Epoch 91/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3428 - output_1_accuracy: 0.7032 - output_1_loss: 0.7830 - output_2_accuracy: 0.7986 - output_2_loss: 0.5598\n",
            "Epoch 92/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.3347 - output_1_accuracy: 0.7054 - output_1_loss: 0.7770 - output_2_accuracy: 0.7982 - output_2_loss: 0.5577\n",
            "Epoch 93/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3123 - output_1_accuracy: 0.7150 - output_1_loss: 0.7630 - output_2_accuracy: 0.8035 - output_2_loss: 0.5493\n",
            "Epoch 94/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3138 - output_1_accuracy: 0.7105 - output_1_loss: 0.7628 - output_2_accuracy: 0.8022 - output_2_loss: 0.5510\n",
            "Epoch 95/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3199 - output_1_accuracy: 0.7024 - output_1_loss: 0.7760 - output_2_accuracy: 0.8055 - output_2_loss: 0.5440\n",
            "Epoch 96/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3016 - output_1_accuracy: 0.7195 - output_1_loss: 0.7503 - output_2_accuracy: 0.8015 - output_2_loss: 0.5513\n",
            "Epoch 97/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3117 - output_1_accuracy: 0.7145 - output_1_loss: 0.7559 - output_2_accuracy: 0.8038 - output_2_loss: 0.5559\n",
            "Epoch 98/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2961 - output_1_accuracy: 0.7207 - output_1_loss: 0.7412 - output_2_accuracy: 0.8032 - output_2_loss: 0.5550\n",
            "Epoch 99/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3180 - output_1_accuracy: 0.7112 - output_1_loss: 0.7654 - output_2_accuracy: 0.7993 - output_2_loss: 0.5526\n",
            "Epoch 100/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.3236 - output_1_accuracy: 0.7137 - output_1_loss: 0.7572 - output_2_accuracy: 0.7944 - output_2_loss: 0.5664\n",
            "Epoch 101/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2913 - output_1_accuracy: 0.7218 - output_1_loss: 0.7453 - output_2_accuracy: 0.8030 - output_2_loss: 0.5460\n",
            "Epoch 102/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2845 - output_1_accuracy: 0.7204 - output_1_loss: 0.7434 - output_2_accuracy: 0.8036 - output_2_loss: 0.5411\n",
            "Epoch 103/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2776 - output_1_accuracy: 0.7205 - output_1_loss: 0.7431 - output_2_accuracy: 0.8063 - output_2_loss: 0.5345\n",
            "Epoch 104/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2916 - output_1_accuracy: 0.7207 - output_1_loss: 0.7454 - output_2_accuracy: 0.8031 - output_2_loss: 0.5462\n",
            "Epoch 105/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2953 - output_1_accuracy: 0.7150 - output_1_loss: 0.7518 - output_2_accuracy: 0.8042 - output_2_loss: 0.5435\n",
            "Epoch 106/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2835 - output_1_accuracy: 0.7148 - output_1_loss: 0.7467 - output_2_accuracy: 0.8066 - output_2_loss: 0.5368\n",
            "Epoch 107/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.3027 - output_1_accuracy: 0.7124 - output_1_loss: 0.7538 - output_2_accuracy: 0.7981 - output_2_loss: 0.5490\n",
            "Epoch 108/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2933 - output_1_accuracy: 0.7159 - output_1_loss: 0.7601 - output_2_accuracy: 0.8112 - output_2_loss: 0.5332\n",
            "Epoch 109/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2754 - output_1_accuracy: 0.7194 - output_1_loss: 0.7369 - output_2_accuracy: 0.8070 - output_2_loss: 0.5385\n",
            "Epoch 110/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2782 - output_1_accuracy: 0.7219 - output_1_loss: 0.7380 - output_2_accuracy: 0.8086 - output_2_loss: 0.5402\n",
            "Epoch 111/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2763 - output_1_accuracy: 0.7143 - output_1_loss: 0.7446 - output_2_accuracy: 0.8112 - output_2_loss: 0.5317\n",
            "Epoch 112/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2598 - output_1_accuracy: 0.7243 - output_1_loss: 0.7310 - output_2_accuracy: 0.8113 - output_2_loss: 0.5288\n",
            "Epoch 113/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2741 - output_1_accuracy: 0.7132 - output_1_loss: 0.7466 - output_2_accuracy: 0.8124 - output_2_loss: 0.5274\n",
            "Epoch 114/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2878 - output_1_accuracy: 0.7116 - output_1_loss: 0.7628 - output_2_accuracy: 0.8100 - output_2_loss: 0.5250\n",
            "Epoch 115/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2963 - output_1_accuracy: 0.7173 - output_1_loss: 0.7481 - output_2_accuracy: 0.8060 - output_2_loss: 0.5482\n",
            "Epoch 116/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2631 - output_1_accuracy: 0.7225 - output_1_loss: 0.7363 - output_2_accuracy: 0.8100 - output_2_loss: 0.5268\n",
            "Epoch 117/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2844 - output_1_accuracy: 0.7120 - output_1_loss: 0.7470 - output_2_accuracy: 0.8092 - output_2_loss: 0.5374\n",
            "Epoch 118/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2561 - output_1_accuracy: 0.7214 - output_1_loss: 0.7391 - output_2_accuracy: 0.8116 - output_2_loss: 0.5171\n",
            "Epoch 119/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2785 - output_1_accuracy: 0.7142 - output_1_loss: 0.7468 - output_2_accuracy: 0.8075 - output_2_loss: 0.5317\n",
            "Epoch 120/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2645 - output_1_accuracy: 0.7209 - output_1_loss: 0.7434 - output_2_accuracy: 0.8128 - output_2_loss: 0.5211\n",
            "Epoch 121/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2477 - output_1_accuracy: 0.7285 - output_1_loss: 0.7244 - output_2_accuracy: 0.8133 - output_2_loss: 0.5234\n",
            "Epoch 122/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2778 - output_1_accuracy: 0.7188 - output_1_loss: 0.7447 - output_2_accuracy: 0.8096 - output_2_loss: 0.5331\n",
            "Epoch 123/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2787 - output_1_accuracy: 0.7140 - output_1_loss: 0.7527 - output_2_accuracy: 0.8107 - output_2_loss: 0.5260\n",
            "Epoch 124/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2627 - output_1_accuracy: 0.7228 - output_1_loss: 0.7330 - output_2_accuracy: 0.8092 - output_2_loss: 0.5297\n",
            "Epoch 125/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2373 - output_1_accuracy: 0.7302 - output_1_loss: 0.7244 - output_2_accuracy: 0.8175 - output_2_loss: 0.5129\n",
            "Epoch 126/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2672 - output_1_accuracy: 0.7208 - output_1_loss: 0.7303 - output_2_accuracy: 0.8088 - output_2_loss: 0.5370\n",
            "Epoch 127/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2433 - output_1_accuracy: 0.7298 - output_1_loss: 0.7147 - output_2_accuracy: 0.8096 - output_2_loss: 0.5286\n",
            "Epoch 128/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2538 - output_1_accuracy: 0.7286 - output_1_loss: 0.7302 - output_2_accuracy: 0.8143 - output_2_loss: 0.5236\n",
            "Epoch 129/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2420 - output_1_accuracy: 0.7311 - output_1_loss: 0.7144 - output_2_accuracy: 0.8120 - output_2_loss: 0.5276\n",
            "Epoch 130/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2705 - output_1_accuracy: 0.7194 - output_1_loss: 0.7368 - output_2_accuracy: 0.8094 - output_2_loss: 0.5337\n",
            "Epoch 131/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2564 - output_1_accuracy: 0.7214 - output_1_loss: 0.7359 - output_2_accuracy: 0.8162 - output_2_loss: 0.5205\n",
            "Epoch 132/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2507 - output_1_accuracy: 0.7248 - output_1_loss: 0.7253 - output_2_accuracy: 0.8111 - output_2_loss: 0.5254\n",
            "Epoch 133/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2538 - output_1_accuracy: 0.7211 - output_1_loss: 0.7322 - output_2_accuracy: 0.8160 - output_2_loss: 0.5216\n",
            "Epoch 134/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.2555 - output_1_accuracy: 0.7247 - output_1_loss: 0.7280 - output_2_accuracy: 0.8110 - output_2_loss: 0.5275\n",
            "Epoch 135/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2492 - output_1_accuracy: 0.7266 - output_1_loss: 0.7274 - output_2_accuracy: 0.8186 - output_2_loss: 0.5219\n",
            "Epoch 136/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.2342 - output_1_accuracy: 0.7247 - output_1_loss: 0.7270 - output_2_accuracy: 0.8176 - output_2_loss: 0.5072\n",
            "Epoch 137/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2453 - output_1_accuracy: 0.7272 - output_1_loss: 0.7293 - output_2_accuracy: 0.8165 - output_2_loss: 0.5160\n",
            "Epoch 138/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.2612 - output_1_accuracy: 0.7263 - output_1_loss: 0.7345 - output_2_accuracy: 0.8133 - output_2_loss: 0.5267\n",
            "Epoch 139/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2306 - output_1_accuracy: 0.7354 - output_1_loss: 0.7036 - output_2_accuracy: 0.8139 - output_2_loss: 0.5270\n",
            "Epoch 140/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2377 - output_1_accuracy: 0.7269 - output_1_loss: 0.7243 - output_2_accuracy: 0.8140 - output_2_loss: 0.5134\n",
            "Epoch 141/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2134 - output_1_accuracy: 0.7335 - output_1_loss: 0.7066 - output_2_accuracy: 0.8175 - output_2_loss: 0.5068\n",
            "Epoch 142/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2466 - output_1_accuracy: 0.7305 - output_1_loss: 0.7185 - output_2_accuracy: 0.8146 - output_2_loss: 0.5281\n",
            "Epoch 143/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2346 - output_1_accuracy: 0.7313 - output_1_loss: 0.7156 - output_2_accuracy: 0.8153 - output_2_loss: 0.5190\n",
            "Epoch 144/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2260 - output_1_accuracy: 0.7331 - output_1_loss: 0.7168 - output_2_accuracy: 0.8207 - output_2_loss: 0.5092\n",
            "Epoch 145/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2341 - output_1_accuracy: 0.7323 - output_1_loss: 0.7144 - output_2_accuracy: 0.8111 - output_2_loss: 0.5197\n",
            "Epoch 146/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2403 - output_1_accuracy: 0.7298 - output_1_loss: 0.7202 - output_2_accuracy: 0.8164 - output_2_loss: 0.5201\n",
            "Epoch 147/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2289 - output_1_accuracy: 0.7317 - output_1_loss: 0.7172 - output_2_accuracy: 0.8186 - output_2_loss: 0.5118\n",
            "Epoch 148/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2347 - output_1_accuracy: 0.7290 - output_1_loss: 0.7167 - output_2_accuracy: 0.8154 - output_2_loss: 0.5181\n",
            "Epoch 149/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2328 - output_1_accuracy: 0.7342 - output_1_loss: 0.7157 - output_2_accuracy: 0.8173 - output_2_loss: 0.5171\n",
            "Epoch 150/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2365 - output_1_accuracy: 0.7316 - output_1_loss: 0.7237 - output_2_accuracy: 0.8220 - output_2_loss: 0.5127\n",
            "Epoch 151/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2195 - output_1_accuracy: 0.7367 - output_1_loss: 0.7123 - output_2_accuracy: 0.8193 - output_2_loss: 0.5072\n",
            "Epoch 152/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2074 - output_1_accuracy: 0.7265 - output_1_loss: 0.7139 - output_2_accuracy: 0.8266 - output_2_loss: 0.4936\n",
            "Epoch 153/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2219 - output_1_accuracy: 0.7329 - output_1_loss: 0.7154 - output_2_accuracy: 0.8207 - output_2_loss: 0.5065\n",
            "Epoch 154/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2009 - output_1_accuracy: 0.7364 - output_1_loss: 0.6988 - output_2_accuracy: 0.8202 - output_2_loss: 0.5021\n",
            "Epoch 155/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.1811 - output_1_accuracy: 0.7367 - output_1_loss: 0.7016 - output_2_accuracy: 0.8307 - output_2_loss: 0.4794\n",
            "Epoch 156/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2192 - output_1_accuracy: 0.7325 - output_1_loss: 0.7086 - output_2_accuracy: 0.8166 - output_2_loss: 0.5106\n",
            "Epoch 157/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.2087 - output_1_accuracy: 0.7296 - output_1_loss: 0.7123 - output_2_accuracy: 0.8224 - output_2_loss: 0.4963\n",
            "Epoch 158/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2057 - output_1_accuracy: 0.7361 - output_1_loss: 0.7004 - output_2_accuracy: 0.8125 - output_2_loss: 0.5053\n",
            "Epoch 159/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2255 - output_1_accuracy: 0.7327 - output_1_loss: 0.7166 - output_2_accuracy: 0.8144 - output_2_loss: 0.5090\n",
            "Epoch 160/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.2070 - output_1_accuracy: 0.7357 - output_1_loss: 0.7071 - output_2_accuracy: 0.8227 - output_2_loss: 0.5000\n",
            "Epoch 161/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2225 - output_1_accuracy: 0.7304 - output_1_loss: 0.7189 - output_2_accuracy: 0.8206 - output_2_loss: 0.5036\n",
            "Epoch 162/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2091 - output_1_accuracy: 0.7337 - output_1_loss: 0.7053 - output_2_accuracy: 0.8167 - output_2_loss: 0.5038\n",
            "Epoch 163/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2109 - output_1_accuracy: 0.7294 - output_1_loss: 0.7154 - output_2_accuracy: 0.8221 - output_2_loss: 0.4955\n",
            "Epoch 164/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2179 - output_1_accuracy: 0.7318 - output_1_loss: 0.7155 - output_2_accuracy: 0.8209 - output_2_loss: 0.5023\n",
            "Epoch 165/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1933 - output_1_accuracy: 0.7363 - output_1_loss: 0.6979 - output_2_accuracy: 0.8219 - output_2_loss: 0.4954\n",
            "Epoch 166/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2270 - output_1_accuracy: 0.7288 - output_1_loss: 0.7159 - output_2_accuracy: 0.8191 - output_2_loss: 0.5112\n",
            "Epoch 167/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1931 - output_1_accuracy: 0.7410 - output_1_loss: 0.6868 - output_2_accuracy: 0.8192 - output_2_loss: 0.5062\n",
            "Epoch 168/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2190 - output_1_accuracy: 0.7257 - output_1_loss: 0.7169 - output_2_accuracy: 0.8210 - output_2_loss: 0.5020\n",
            "Epoch 169/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2186 - output_1_accuracy: 0.7317 - output_1_loss: 0.7126 - output_2_accuracy: 0.8172 - output_2_loss: 0.5059\n",
            "Epoch 170/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1880 - output_1_accuracy: 0.7426 - output_1_loss: 0.6923 - output_2_accuracy: 0.8246 - output_2_loss: 0.4957\n",
            "Epoch 171/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2064 - output_1_accuracy: 0.7378 - output_1_loss: 0.7047 - output_2_accuracy: 0.8222 - output_2_loss: 0.5017\n",
            "Epoch 172/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.2139 - output_1_accuracy: 0.7318 - output_1_loss: 0.7087 - output_2_accuracy: 0.8204 - output_2_loss: 0.5052\n",
            "Epoch 173/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1812 - output_1_accuracy: 0.7421 - output_1_loss: 0.6951 - output_2_accuracy: 0.8261 - output_2_loss: 0.4860\n",
            "Epoch 174/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1909 - output_1_accuracy: 0.7366 - output_1_loss: 0.7010 - output_2_accuracy: 0.8285 - output_2_loss: 0.4899\n",
            "Epoch 175/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1969 - output_1_accuracy: 0.7323 - output_1_loss: 0.7096 - output_2_accuracy: 0.8262 - output_2_loss: 0.4873\n",
            "Epoch 176/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1997 - output_1_accuracy: 0.7329 - output_1_loss: 0.7069 - output_2_accuracy: 0.8270 - output_2_loss: 0.4927\n",
            "Epoch 177/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2024 - output_1_accuracy: 0.7364 - output_1_loss: 0.7017 - output_2_accuracy: 0.8221 - output_2_loss: 0.5007\n",
            "Epoch 178/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1598 - output_1_accuracy: 0.7430 - output_1_loss: 0.6801 - output_2_accuracy: 0.8292 - output_2_loss: 0.4797\n",
            "Epoch 179/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1690 - output_1_accuracy: 0.7421 - output_1_loss: 0.6787 - output_2_accuracy: 0.8261 - output_2_loss: 0.4903\n",
            "Epoch 180/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1903 - output_1_accuracy: 0.7405 - output_1_loss: 0.6921 - output_2_accuracy: 0.8215 - output_2_loss: 0.4982\n",
            "Epoch 181/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1809 - output_1_accuracy: 0.7481 - output_1_loss: 0.6812 - output_2_accuracy: 0.8252 - output_2_loss: 0.4997\n",
            "Epoch 182/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1723 - output_1_accuracy: 0.7411 - output_1_loss: 0.6923 - output_2_accuracy: 0.8269 - output_2_loss: 0.4801\n",
            "Epoch 183/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1718 - output_1_accuracy: 0.7428 - output_1_loss: 0.6832 - output_2_accuracy: 0.8301 - output_2_loss: 0.4887\n",
            "Epoch 184/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1809 - output_1_accuracy: 0.7407 - output_1_loss: 0.6921 - output_2_accuracy: 0.8246 - output_2_loss: 0.4889\n",
            "Epoch 185/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2005 - output_1_accuracy: 0.7385 - output_1_loss: 0.7011 - output_2_accuracy: 0.8210 - output_2_loss: 0.4993\n",
            "Epoch 186/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1708 - output_1_accuracy: 0.7366 - output_1_loss: 0.6895 - output_2_accuracy: 0.8285 - output_2_loss: 0.4812\n",
            "Epoch 187/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1857 - output_1_accuracy: 0.7436 - output_1_loss: 0.6862 - output_2_accuracy: 0.8183 - output_2_loss: 0.4995\n",
            "Epoch 188/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1804 - output_1_accuracy: 0.7439 - output_1_loss: 0.6866 - output_2_accuracy: 0.8247 - output_2_loss: 0.4938\n",
            "Epoch 189/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1627 - output_1_accuracy: 0.7482 - output_1_loss: 0.6721 - output_2_accuracy: 0.8228 - output_2_loss: 0.4905\n",
            "Epoch 190/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1836 - output_1_accuracy: 0.7430 - output_1_loss: 0.6848 - output_2_accuracy: 0.8194 - output_2_loss: 0.4988\n",
            "Epoch 191/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1916 - output_1_accuracy: 0.7370 - output_1_loss: 0.7042 - output_2_accuracy: 0.8270 - output_2_loss: 0.4874\n",
            "Epoch 192/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1748 - output_1_accuracy: 0.7335 - output_1_loss: 0.6957 - output_2_accuracy: 0.8291 - output_2_loss: 0.4791\n",
            "Epoch 193/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1594 - output_1_accuracy: 0.7379 - output_1_loss: 0.6929 - output_2_accuracy: 0.8350 - output_2_loss: 0.4665\n",
            "Epoch 194/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1701 - output_1_accuracy: 0.7514 - output_1_loss: 0.6790 - output_2_accuracy: 0.8283 - output_2_loss: 0.4911\n",
            "Epoch 195/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.2014 - output_1_accuracy: 0.7356 - output_1_loss: 0.6998 - output_2_accuracy: 0.8200 - output_2_loss: 0.5016\n",
            "Epoch 196/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1543 - output_1_accuracy: 0.7401 - output_1_loss: 0.6886 - output_2_accuracy: 0.8352 - output_2_loss: 0.4657\n",
            "Epoch 197/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1612 - output_1_accuracy: 0.7463 - output_1_loss: 0.6744 - output_2_accuracy: 0.8276 - output_2_loss: 0.4867\n",
            "Epoch 198/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1521 - output_1_accuracy: 0.7444 - output_1_loss: 0.6779 - output_2_accuracy: 0.8286 - output_2_loss: 0.4742\n",
            "Epoch 199/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1980 - output_1_accuracy: 0.7368 - output_1_loss: 0.7055 - output_2_accuracy: 0.8242 - output_2_loss: 0.4925\n",
            "Epoch 200/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1775 - output_1_accuracy: 0.7425 - output_1_loss: 0.6843 - output_2_accuracy: 0.8233 - output_2_loss: 0.4932\n",
            "Epoch 201/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1643 - output_1_accuracy: 0.7432 - output_1_loss: 0.6875 - output_2_accuracy: 0.8343 - output_2_loss: 0.4768\n",
            "Epoch 202/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1610 - output_1_accuracy: 0.7469 - output_1_loss: 0.6811 - output_2_accuracy: 0.8293 - output_2_loss: 0.4799\n",
            "Epoch 203/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1814 - output_1_accuracy: 0.7382 - output_1_loss: 0.6918 - output_2_accuracy: 0.8271 - output_2_loss: 0.4896\n",
            "Epoch 204/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1709 - output_1_accuracy: 0.7441 - output_1_loss: 0.6807 - output_2_accuracy: 0.8252 - output_2_loss: 0.4902\n",
            "Epoch 205/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1676 - output_1_accuracy: 0.7407 - output_1_loss: 0.6879 - output_2_accuracy: 0.8311 - output_2_loss: 0.4797\n",
            "Epoch 206/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1634 - output_1_accuracy: 0.7437 - output_1_loss: 0.6846 - output_2_accuracy: 0.8288 - output_2_loss: 0.4788\n",
            "Epoch 207/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1556 - output_1_accuracy: 0.7476 - output_1_loss: 0.6753 - output_2_accuracy: 0.8287 - output_2_loss: 0.4802\n",
            "Epoch 208/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1574 - output_1_accuracy: 0.7468 - output_1_loss: 0.6761 - output_2_accuracy: 0.8286 - output_2_loss: 0.4813\n",
            "Epoch 209/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1541 - output_1_accuracy: 0.7459 - output_1_loss: 0.6823 - output_2_accuracy: 0.8307 - output_2_loss: 0.4719\n",
            "Epoch 210/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1486 - output_1_accuracy: 0.7416 - output_1_loss: 0.6800 - output_2_accuracy: 0.8364 - output_2_loss: 0.4685\n",
            "Epoch 211/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1612 - output_1_accuracy: 0.7493 - output_1_loss: 0.6711 - output_2_accuracy: 0.8275 - output_2_loss: 0.4901\n",
            "Epoch 212/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1525 - output_1_accuracy: 0.7475 - output_1_loss: 0.6764 - output_2_accuracy: 0.8303 - output_2_loss: 0.4761\n",
            "Epoch 213/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1586 - output_1_accuracy: 0.7424 - output_1_loss: 0.6810 - output_2_accuracy: 0.8282 - output_2_loss: 0.4776\n",
            "Epoch 214/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1566 - output_1_accuracy: 0.7444 - output_1_loss: 0.6748 - output_2_accuracy: 0.8267 - output_2_loss: 0.4818\n",
            "Epoch 215/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1676 - output_1_accuracy: 0.7436 - output_1_loss: 0.6835 - output_2_accuracy: 0.8247 - output_2_loss: 0.4840\n",
            "Epoch 216/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1497 - output_1_accuracy: 0.7448 - output_1_loss: 0.6781 - output_2_accuracy: 0.8299 - output_2_loss: 0.4717\n",
            "Epoch 217/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1646 - output_1_accuracy: 0.7403 - output_1_loss: 0.6865 - output_2_accuracy: 0.8257 - output_2_loss: 0.4781\n",
            "Epoch 218/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1580 - output_1_accuracy: 0.7519 - output_1_loss: 0.6699 - output_2_accuracy: 0.8276 - output_2_loss: 0.4881\n",
            "Epoch 219/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1599 - output_1_accuracy: 0.7456 - output_1_loss: 0.6848 - output_2_accuracy: 0.8304 - output_2_loss: 0.4751\n",
            "Epoch 220/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1525 - output_1_accuracy: 0.7476 - output_1_loss: 0.6840 - output_2_accuracy: 0.8346 - output_2_loss: 0.4685\n",
            "Epoch 221/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1563 - output_1_accuracy: 0.7479 - output_1_loss: 0.6723 - output_2_accuracy: 0.8298 - output_2_loss: 0.4840\n",
            "Epoch 222/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1542 - output_1_accuracy: 0.7404 - output_1_loss: 0.6830 - output_2_accuracy: 0.8291 - output_2_loss: 0.4712\n",
            "Epoch 223/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1476 - output_1_accuracy: 0.7510 - output_1_loss: 0.6680 - output_2_accuracy: 0.8304 - output_2_loss: 0.4796\n",
            "Epoch 224/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1510 - output_1_accuracy: 0.7482 - output_1_loss: 0.6749 - output_2_accuracy: 0.8330 - output_2_loss: 0.4760\n",
            "Epoch 225/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1546 - output_1_accuracy: 0.7416 - output_1_loss: 0.6850 - output_2_accuracy: 0.8325 - output_2_loss: 0.4696\n",
            "Epoch 226/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1510 - output_1_accuracy: 0.7470 - output_1_loss: 0.6743 - output_2_accuracy: 0.8305 - output_2_loss: 0.4767\n",
            "Epoch 227/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1510 - output_1_accuracy: 0.7460 - output_1_loss: 0.6702 - output_2_accuracy: 0.8286 - output_2_loss: 0.4809\n",
            "Epoch 228/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1400 - output_1_accuracy: 0.7481 - output_1_loss: 0.6712 - output_2_accuracy: 0.8307 - output_2_loss: 0.4688\n",
            "Epoch 229/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1370 - output_1_accuracy: 0.7510 - output_1_loss: 0.6698 - output_2_accuracy: 0.8332 - output_2_loss: 0.4673\n",
            "Epoch 230/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1430 - output_1_accuracy: 0.7473 - output_1_loss: 0.6768 - output_2_accuracy: 0.8348 - output_2_loss: 0.4662\n",
            "Epoch 231/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1457 - output_1_accuracy: 0.7482 - output_1_loss: 0.6744 - output_2_accuracy: 0.8314 - output_2_loss: 0.4714\n",
            "Epoch 232/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1330 - output_1_accuracy: 0.7483 - output_1_loss: 0.6804 - output_2_accuracy: 0.8402 - output_2_loss: 0.4526\n",
            "Epoch 233/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1306 - output_1_accuracy: 0.7484 - output_1_loss: 0.6699 - output_2_accuracy: 0.8346 - output_2_loss: 0.4606\n",
            "Epoch 234/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1152 - output_1_accuracy: 0.7562 - output_1_loss: 0.6559 - output_2_accuracy: 0.8364 - output_2_loss: 0.4593\n",
            "Epoch 235/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1440 - output_1_accuracy: 0.7506 - output_1_loss: 0.6692 - output_2_accuracy: 0.8285 - output_2_loss: 0.4748\n",
            "Epoch 236/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1487 - output_1_accuracy: 0.7423 - output_1_loss: 0.6782 - output_2_accuracy: 0.8304 - output_2_loss: 0.4705\n",
            "Epoch 237/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1379 - output_1_accuracy: 0.7515 - output_1_loss: 0.6638 - output_2_accuracy: 0.8318 - output_2_loss: 0.4742\n",
            "Epoch 238/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1504 - output_1_accuracy: 0.7464 - output_1_loss: 0.6735 - output_2_accuracy: 0.8318 - output_2_loss: 0.4769\n",
            "Epoch 239/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1469 - output_1_accuracy: 0.7475 - output_1_loss: 0.6759 - output_2_accuracy: 0.8336 - output_2_loss: 0.4711\n",
            "Epoch 240/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1299 - output_1_accuracy: 0.7495 - output_1_loss: 0.6683 - output_2_accuracy: 0.8334 - output_2_loss: 0.4616\n",
            "Epoch 241/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1316 - output_1_accuracy: 0.7542 - output_1_loss: 0.6568 - output_2_accuracy: 0.8329 - output_2_loss: 0.4748\n",
            "Epoch 242/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1328 - output_1_accuracy: 0.7524 - output_1_loss: 0.6657 - output_2_accuracy: 0.8339 - output_2_loss: 0.4671\n",
            "Epoch 243/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1424 - output_1_accuracy: 0.7474 - output_1_loss: 0.6700 - output_2_accuracy: 0.8339 - output_2_loss: 0.4724\n",
            "Epoch 244/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 1.1273 - output_1_accuracy: 0.7426 - output_1_loss: 0.6758 - output_2_accuracy: 0.8378 - output_2_loss: 0.4514\n",
            "Epoch 245/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1435 - output_1_accuracy: 0.7475 - output_1_loss: 0.6810 - output_2_accuracy: 0.8383 - output_2_loss: 0.4625\n",
            "Epoch 246/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1169 - output_1_accuracy: 0.7577 - output_1_loss: 0.6569 - output_2_accuracy: 0.8363 - output_2_loss: 0.4600\n",
            "Epoch 247/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1375 - output_1_accuracy: 0.7510 - output_1_loss: 0.6622 - output_2_accuracy: 0.8318 - output_2_loss: 0.4753\n",
            "Epoch 248/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1400 - output_1_accuracy: 0.7533 - output_1_loss: 0.6643 - output_2_accuracy: 0.8249 - output_2_loss: 0.4758\n",
            "Epoch 249/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1374 - output_1_accuracy: 0.7545 - output_1_loss: 0.6600 - output_2_accuracy: 0.8269 - output_2_loss: 0.4774\n",
            "Epoch 250/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1228 - output_1_accuracy: 0.7586 - output_1_loss: 0.6507 - output_2_accuracy: 0.8351 - output_2_loss: 0.4721\n",
            "Epoch 251/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1270 - output_1_accuracy: 0.7523 - output_1_loss: 0.6702 - output_2_accuracy: 0.8380 - output_2_loss: 0.4568\n",
            "Epoch 252/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1161 - output_1_accuracy: 0.7497 - output_1_loss: 0.6609 - output_2_accuracy: 0.8365 - output_2_loss: 0.4552\n",
            "Epoch 253/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1441 - output_1_accuracy: 0.7488 - output_1_loss: 0.6690 - output_2_accuracy: 0.8271 - output_2_loss: 0.4750\n",
            "Epoch 254/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1312 - output_1_accuracy: 0.7531 - output_1_loss: 0.6594 - output_2_accuracy: 0.8325 - output_2_loss: 0.4717\n",
            "Epoch 255/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1452 - output_1_accuracy: 0.7488 - output_1_loss: 0.6719 - output_2_accuracy: 0.8302 - output_2_loss: 0.4733\n",
            "Epoch 256/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1299 - output_1_accuracy: 0.7526 - output_1_loss: 0.6613 - output_2_accuracy: 0.8300 - output_2_loss: 0.4686\n",
            "Epoch 257/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1061 - output_1_accuracy: 0.7555 - output_1_loss: 0.6572 - output_2_accuracy: 0.8413 - output_2_loss: 0.4490\n",
            "Epoch 258/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1229 - output_1_accuracy: 0.7577 - output_1_loss: 0.6513 - output_2_accuracy: 0.8292 - output_2_loss: 0.4716\n",
            "Epoch 259/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1346 - output_1_accuracy: 0.7539 - output_1_loss: 0.6659 - output_2_accuracy: 0.8324 - output_2_loss: 0.4688\n",
            "Epoch 260/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1164 - output_1_accuracy: 0.7519 - output_1_loss: 0.6576 - output_2_accuracy: 0.8368 - output_2_loss: 0.4589\n",
            "Epoch 261/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1245 - output_1_accuracy: 0.7505 - output_1_loss: 0.6599 - output_2_accuracy: 0.8335 - output_2_loss: 0.4646\n",
            "Epoch 262/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1094 - output_1_accuracy: 0.7611 - output_1_loss: 0.6448 - output_2_accuracy: 0.8345 - output_2_loss: 0.4646\n",
            "Epoch 263/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1238 - output_1_accuracy: 0.7542 - output_1_loss: 0.6673 - output_2_accuracy: 0.8409 - output_2_loss: 0.4566\n",
            "Epoch 264/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1213 - output_1_accuracy: 0.7553 - output_1_loss: 0.6527 - output_2_accuracy: 0.8317 - output_2_loss: 0.4686\n",
            "Epoch 265/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1173 - output_1_accuracy: 0.7519 - output_1_loss: 0.6576 - output_2_accuracy: 0.8373 - output_2_loss: 0.4596\n",
            "Epoch 266/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1285 - output_1_accuracy: 0.7546 - output_1_loss: 0.6506 - output_2_accuracy: 0.8293 - output_2_loss: 0.4779\n",
            "Epoch 267/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1065 - output_1_accuracy: 0.7565 - output_1_loss: 0.6433 - output_2_accuracy: 0.8344 - output_2_loss: 0.4631\n",
            "Epoch 268/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1231 - output_1_accuracy: 0.7577 - output_1_loss: 0.6561 - output_2_accuracy: 0.8336 - output_2_loss: 0.4669\n",
            "Epoch 269/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1166 - output_1_accuracy: 0.7557 - output_1_loss: 0.6533 - output_2_accuracy: 0.8347 - output_2_loss: 0.4633\n",
            "Epoch 270/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1169 - output_1_accuracy: 0.7555 - output_1_loss: 0.6550 - output_2_accuracy: 0.8390 - output_2_loss: 0.4619\n",
            "Epoch 271/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1212 - output_1_accuracy: 0.7558 - output_1_loss: 0.6540 - output_2_accuracy: 0.8346 - output_2_loss: 0.4672\n",
            "Epoch 272/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1300 - output_1_accuracy: 0.7532 - output_1_loss: 0.6619 - output_2_accuracy: 0.8363 - output_2_loss: 0.4681\n",
            "Epoch 273/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1213 - output_1_accuracy: 0.7510 - output_1_loss: 0.6633 - output_2_accuracy: 0.8368 - output_2_loss: 0.4580\n",
            "Epoch 274/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1224 - output_1_accuracy: 0.7559 - output_1_loss: 0.6532 - output_2_accuracy: 0.8356 - output_2_loss: 0.4692\n",
            "Epoch 275/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1239 - output_1_accuracy: 0.7550 - output_1_loss: 0.6623 - output_2_accuracy: 0.8362 - output_2_loss: 0.4615\n",
            "Epoch 276/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1186 - output_1_accuracy: 0.7586 - output_1_loss: 0.6515 - output_2_accuracy: 0.8358 - output_2_loss: 0.4671\n",
            "Epoch 277/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1239 - output_1_accuracy: 0.7592 - output_1_loss: 0.6586 - output_2_accuracy: 0.8340 - output_2_loss: 0.4653\n",
            "Epoch 278/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1128 - output_1_accuracy: 0.7554 - output_1_loss: 0.6471 - output_2_accuracy: 0.8347 - output_2_loss: 0.4657\n",
            "Epoch 279/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1231 - output_1_accuracy: 0.7593 - output_1_loss: 0.6454 - output_2_accuracy: 0.8325 - output_2_loss: 0.4777\n",
            "Epoch 280/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1073 - output_1_accuracy: 0.7527 - output_1_loss: 0.6593 - output_2_accuracy: 0.8407 - output_2_loss: 0.4480\n",
            "Epoch 281/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1021 - output_1_accuracy: 0.7603 - output_1_loss: 0.6434 - output_2_accuracy: 0.8361 - output_2_loss: 0.4587\n",
            "Epoch 282/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1157 - output_1_accuracy: 0.7591 - output_1_loss: 0.6514 - output_2_accuracy: 0.8370 - output_2_loss: 0.4643\n",
            "Epoch 283/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0989 - output_1_accuracy: 0.7621 - output_1_loss: 0.6446 - output_2_accuracy: 0.8357 - output_2_loss: 0.4543\n",
            "Epoch 284/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1253 - output_1_accuracy: 0.7530 - output_1_loss: 0.6684 - output_2_accuracy: 0.8377 - output_2_loss: 0.4569\n",
            "Epoch 285/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1122 - output_1_accuracy: 0.7580 - output_1_loss: 0.6484 - output_2_accuracy: 0.8342 - output_2_loss: 0.4638\n",
            "Epoch 286/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0876 - output_1_accuracy: 0.7590 - output_1_loss: 0.6380 - output_2_accuracy: 0.8407 - output_2_loss: 0.4497\n",
            "Epoch 287/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1038 - output_1_accuracy: 0.7567 - output_1_loss: 0.6556 - output_2_accuracy: 0.8398 - output_2_loss: 0.4482\n",
            "Epoch 288/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1022 - output_1_accuracy: 0.7595 - output_1_loss: 0.6502 - output_2_accuracy: 0.8380 - output_2_loss: 0.4520\n",
            "Epoch 289/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1127 - output_1_accuracy: 0.7555 - output_1_loss: 0.6560 - output_2_accuracy: 0.8398 - output_2_loss: 0.4566\n",
            "Epoch 290/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1259 - output_1_accuracy: 0.7581 - output_1_loss: 0.6551 - output_2_accuracy: 0.8322 - output_2_loss: 0.4708\n",
            "Epoch 291/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0926 - output_1_accuracy: 0.7590 - output_1_loss: 0.6462 - output_2_accuracy: 0.8416 - output_2_loss: 0.4463\n",
            "Epoch 292/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0901 - output_1_accuracy: 0.7568 - output_1_loss: 0.6509 - output_2_accuracy: 0.8428 - output_2_loss: 0.4393\n",
            "Epoch 293/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0915 - output_1_accuracy: 0.7562 - output_1_loss: 0.6465 - output_2_accuracy: 0.8422 - output_2_loss: 0.4450\n",
            "Epoch 294/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1020 - output_1_accuracy: 0.7598 - output_1_loss: 0.6434 - output_2_accuracy: 0.8387 - output_2_loss: 0.4586\n",
            "Epoch 295/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1164 - output_1_accuracy: 0.7537 - output_1_loss: 0.6647 - output_2_accuracy: 0.8396 - output_2_loss: 0.4517\n",
            "Epoch 296/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1059 - output_1_accuracy: 0.7588 - output_1_loss: 0.6545 - output_2_accuracy: 0.8425 - output_2_loss: 0.4514\n",
            "Epoch 297/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.1220 - output_1_accuracy: 0.7524 - output_1_loss: 0.6595 - output_2_accuracy: 0.8370 - output_2_loss: 0.4625\n",
            "Epoch 298/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0912 - output_1_accuracy: 0.7643 - output_1_loss: 0.6396 - output_2_accuracy: 0.8399 - output_2_loss: 0.4516\n",
            "Epoch 299/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0958 - output_1_accuracy: 0.7601 - output_1_loss: 0.6459 - output_2_accuracy: 0.8399 - output_2_loss: 0.4499\n",
            "Epoch 300/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1231 - output_1_accuracy: 0.7522 - output_1_loss: 0.6638 - output_2_accuracy: 0.8354 - output_2_loss: 0.4593\n",
            "Epoch 301/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0975 - output_1_accuracy: 0.7633 - output_1_loss: 0.6441 - output_2_accuracy: 0.8390 - output_2_loss: 0.4535\n",
            "Epoch 302/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1059 - output_1_accuracy: 0.7548 - output_1_loss: 0.6525 - output_2_accuracy: 0.8439 - output_2_loss: 0.4534\n",
            "Epoch 303/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0928 - output_1_accuracy: 0.7571 - output_1_loss: 0.6453 - output_2_accuracy: 0.8400 - output_2_loss: 0.4475\n",
            "Epoch 304/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0881 - output_1_accuracy: 0.7674 - output_1_loss: 0.6354 - output_2_accuracy: 0.8397 - output_2_loss: 0.4526\n",
            "Epoch 305/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0865 - output_1_accuracy: 0.7632 - output_1_loss: 0.6356 - output_2_accuracy: 0.8371 - output_2_loss: 0.4509\n",
            "Epoch 306/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1102 - output_1_accuracy: 0.7602 - output_1_loss: 0.6564 - output_2_accuracy: 0.8346 - output_2_loss: 0.4538\n",
            "Epoch 307/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1019 - output_1_accuracy: 0.7610 - output_1_loss: 0.6435 - output_2_accuracy: 0.8372 - output_2_loss: 0.4584\n",
            "Epoch 308/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0733 - output_1_accuracy: 0.7653 - output_1_loss: 0.6254 - output_2_accuracy: 0.8433 - output_2_loss: 0.4480\n",
            "Epoch 309/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1112 - output_1_accuracy: 0.7533 - output_1_loss: 0.6568 - output_2_accuracy: 0.8383 - output_2_loss: 0.4544\n",
            "Epoch 310/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0865 - output_1_accuracy: 0.7647 - output_1_loss: 0.6398 - output_2_accuracy: 0.8413 - output_2_loss: 0.4467\n",
            "Epoch 311/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0804 - output_1_accuracy: 0.7570 - output_1_loss: 0.6421 - output_2_accuracy: 0.8444 - output_2_loss: 0.4383\n",
            "Epoch 312/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1051 - output_1_accuracy: 0.7597 - output_1_loss: 0.6425 - output_2_accuracy: 0.8388 - output_2_loss: 0.4625\n",
            "Epoch 313/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1022 - output_1_accuracy: 0.7569 - output_1_loss: 0.6456 - output_2_accuracy: 0.8408 - output_2_loss: 0.4567\n",
            "Epoch 314/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0940 - output_1_accuracy: 0.7561 - output_1_loss: 0.6484 - output_2_accuracy: 0.8424 - output_2_loss: 0.4456\n",
            "Epoch 315/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0884 - output_1_accuracy: 0.7616 - output_1_loss: 0.6435 - output_2_accuracy: 0.8422 - output_2_loss: 0.4449\n",
            "Epoch 316/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0960 - output_1_accuracy: 0.7588 - output_1_loss: 0.6457 - output_2_accuracy: 0.8374 - output_2_loss: 0.4504\n",
            "Epoch 317/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0872 - output_1_accuracy: 0.7654 - output_1_loss: 0.6351 - output_2_accuracy: 0.8387 - output_2_loss: 0.4521\n",
            "Epoch 318/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0895 - output_1_accuracy: 0.7638 - output_1_loss: 0.6413 - output_2_accuracy: 0.8397 - output_2_loss: 0.4482\n",
            "Epoch 319/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0771 - output_1_accuracy: 0.7592 - output_1_loss: 0.6462 - output_2_accuracy: 0.8492 - output_2_loss: 0.4308\n",
            "Epoch 320/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0919 - output_1_accuracy: 0.7640 - output_1_loss: 0.6360 - output_2_accuracy: 0.8390 - output_2_loss: 0.4558\n",
            "Epoch 321/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1164 - output_1_accuracy: 0.7564 - output_1_loss: 0.6576 - output_2_accuracy: 0.8421 - output_2_loss: 0.4588\n",
            "Epoch 322/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1045 - output_1_accuracy: 0.7616 - output_1_loss: 0.6516 - output_2_accuracy: 0.8423 - output_2_loss: 0.4530\n",
            "Epoch 323/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1009 - output_1_accuracy: 0.7627 - output_1_loss: 0.6434 - output_2_accuracy: 0.8353 - output_2_loss: 0.4574\n",
            "Epoch 324/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0895 - output_1_accuracy: 0.7632 - output_1_loss: 0.6454 - output_2_accuracy: 0.8402 - output_2_loss: 0.4441\n",
            "Epoch 325/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0982 - output_1_accuracy: 0.7610 - output_1_loss: 0.6412 - output_2_accuracy: 0.8386 - output_2_loss: 0.4570\n",
            "Epoch 326/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0957 - output_1_accuracy: 0.7577 - output_1_loss: 0.6396 - output_2_accuracy: 0.8369 - output_2_loss: 0.4561\n",
            "Epoch 327/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0952 - output_1_accuracy: 0.7587 - output_1_loss: 0.6487 - output_2_accuracy: 0.8411 - output_2_loss: 0.4464\n",
            "Epoch 328/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1199 - output_1_accuracy: 0.7593 - output_1_loss: 0.6562 - output_2_accuracy: 0.8373 - output_2_loss: 0.4638\n",
            "Epoch 329/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0823 - output_1_accuracy: 0.7646 - output_1_loss: 0.6364 - output_2_accuracy: 0.8393 - output_2_loss: 0.4459\n",
            "Epoch 330/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0679 - output_1_accuracy: 0.7645 - output_1_loss: 0.6363 - output_2_accuracy: 0.8461 - output_2_loss: 0.4315\n",
            "Epoch 331/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1043 - output_1_accuracy: 0.7527 - output_1_loss: 0.6521 - output_2_accuracy: 0.8385 - output_2_loss: 0.4522\n",
            "Epoch 332/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0881 - output_1_accuracy: 0.7605 - output_1_loss: 0.6316 - output_2_accuracy: 0.8401 - output_2_loss: 0.4565\n",
            "Epoch 333/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1022 - output_1_accuracy: 0.7642 - output_1_loss: 0.6451 - output_2_accuracy: 0.8382 - output_2_loss: 0.4571\n",
            "Epoch 334/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0966 - output_1_accuracy: 0.7553 - output_1_loss: 0.6497 - output_2_accuracy: 0.8388 - output_2_loss: 0.4470\n",
            "Epoch 335/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1022 - output_1_accuracy: 0.7628 - output_1_loss: 0.6398 - output_2_accuracy: 0.8351 - output_2_loss: 0.4624\n",
            "Epoch 336/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0906 - output_1_accuracy: 0.7606 - output_1_loss: 0.6416 - output_2_accuracy: 0.8373 - output_2_loss: 0.4491\n",
            "Epoch 337/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0791 - output_1_accuracy: 0.7626 - output_1_loss: 0.6377 - output_2_accuracy: 0.8446 - output_2_loss: 0.4414\n",
            "Epoch 338/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0879 - output_1_accuracy: 0.7647 - output_1_loss: 0.6329 - output_2_accuracy: 0.8368 - output_2_loss: 0.4551\n",
            "Epoch 339/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0698 - output_1_accuracy: 0.7688 - output_1_loss: 0.6313 - output_2_accuracy: 0.8450 - output_2_loss: 0.4385\n",
            "Epoch 340/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0828 - output_1_accuracy: 0.7612 - output_1_loss: 0.6432 - output_2_accuracy: 0.8425 - output_2_loss: 0.4396\n",
            "Epoch 341/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0956 - output_1_accuracy: 0.7596 - output_1_loss: 0.6387 - output_2_accuracy: 0.8387 - output_2_loss: 0.4569\n",
            "Epoch 342/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0718 - output_1_accuracy: 0.7635 - output_1_loss: 0.6328 - output_2_accuracy: 0.8412 - output_2_loss: 0.4389\n",
            "Epoch 343/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0753 - output_1_accuracy: 0.7619 - output_1_loss: 0.6315 - output_2_accuracy: 0.8412 - output_2_loss: 0.4439\n",
            "Epoch 344/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0683 - output_1_accuracy: 0.7693 - output_1_loss: 0.6223 - output_2_accuracy: 0.8431 - output_2_loss: 0.4460\n",
            "Epoch 345/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0739 - output_1_accuracy: 0.7663 - output_1_loss: 0.6253 - output_2_accuracy: 0.8441 - output_2_loss: 0.4485\n",
            "Epoch 346/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0729 - output_1_accuracy: 0.7611 - output_1_loss: 0.6377 - output_2_accuracy: 0.8410 - output_2_loss: 0.4351\n",
            "Epoch 347/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0877 - output_1_accuracy: 0.7624 - output_1_loss: 0.6451 - output_2_accuracy: 0.8452 - output_2_loss: 0.4426\n",
            "Epoch 348/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0856 - output_1_accuracy: 0.7619 - output_1_loss: 0.6429 - output_2_accuracy: 0.8409 - output_2_loss: 0.4427\n",
            "Epoch 349/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0828 - output_1_accuracy: 0.7620 - output_1_loss: 0.6406 - output_2_accuracy: 0.8440 - output_2_loss: 0.4422\n",
            "Epoch 350/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 1.0903 - output_1_accuracy: 0.7568 - output_1_loss: 0.6505 - output_2_accuracy: 0.8433 - output_2_loss: 0.4398\n",
            "Epoch 351/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0734 - output_1_accuracy: 0.7605 - output_1_loss: 0.6304 - output_2_accuracy: 0.8423 - output_2_loss: 0.4430\n",
            "Epoch 352/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0762 - output_1_accuracy: 0.7634 - output_1_loss: 0.6271 - output_2_accuracy: 0.8414 - output_2_loss: 0.4491\n",
            "Epoch 353/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0997 - output_1_accuracy: 0.7641 - output_1_loss: 0.6355 - output_2_accuracy: 0.8349 - output_2_loss: 0.4641\n",
            "Epoch 354/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0556 - output_1_accuracy: 0.7667 - output_1_loss: 0.6259 - output_2_accuracy: 0.8467 - output_2_loss: 0.4297\n",
            "Epoch 355/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0672 - output_1_accuracy: 0.7652 - output_1_loss: 0.6357 - output_2_accuracy: 0.8513 - output_2_loss: 0.4315\n",
            "Epoch 356/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0859 - output_1_accuracy: 0.7613 - output_1_loss: 0.6398 - output_2_accuracy: 0.8389 - output_2_loss: 0.4462\n",
            "Epoch 357/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.1000 - output_1_accuracy: 0.7619 - output_1_loss: 0.6408 - output_2_accuracy: 0.8332 - output_2_loss: 0.4593\n",
            "Epoch 358/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0823 - output_1_accuracy: 0.7613 - output_1_loss: 0.6407 - output_2_accuracy: 0.8414 - output_2_loss: 0.4416\n",
            "Epoch 359/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0700 - output_1_accuracy: 0.7612 - output_1_loss: 0.6273 - output_2_accuracy: 0.8454 - output_2_loss: 0.4427\n",
            "Epoch 360/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0746 - output_1_accuracy: 0.7696 - output_1_loss: 0.6249 - output_2_accuracy: 0.8426 - output_2_loss: 0.4497\n",
            "Epoch 361/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0871 - output_1_accuracy: 0.7653 - output_1_loss: 0.6355 - output_2_accuracy: 0.8404 - output_2_loss: 0.4516\n",
            "Epoch 362/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0901 - output_1_accuracy: 0.7584 - output_1_loss: 0.6477 - output_2_accuracy: 0.8406 - output_2_loss: 0.4424\n",
            "Epoch 363/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0635 - output_1_accuracy: 0.7664 - output_1_loss: 0.6254 - output_2_accuracy: 0.8407 - output_2_loss: 0.4381\n",
            "Epoch 364/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0617 - output_1_accuracy: 0.7660 - output_1_loss: 0.6302 - output_2_accuracy: 0.8460 - output_2_loss: 0.4316\n",
            "Epoch 365/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0624 - output_1_accuracy: 0.7644 - output_1_loss: 0.6192 - output_2_accuracy: 0.8435 - output_2_loss: 0.4432\n",
            "Epoch 366/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0745 - output_1_accuracy: 0.7658 - output_1_loss: 0.6288 - output_2_accuracy: 0.8416 - output_2_loss: 0.4457\n",
            "Epoch 367/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0620 - output_1_accuracy: 0.7679 - output_1_loss: 0.6274 - output_2_accuracy: 0.8439 - output_2_loss: 0.4346\n",
            "Epoch 368/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0735 - output_1_accuracy: 0.7666 - output_1_loss: 0.6325 - output_2_accuracy: 0.8409 - output_2_loss: 0.4410\n",
            "Epoch 369/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0549 - output_1_accuracy: 0.7686 - output_1_loss: 0.6179 - output_2_accuracy: 0.8427 - output_2_loss: 0.4369\n",
            "Epoch 370/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0599 - output_1_accuracy: 0.7631 - output_1_loss: 0.6272 - output_2_accuracy: 0.8420 - output_2_loss: 0.4327\n",
            "Epoch 371/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0749 - output_1_accuracy: 0.7637 - output_1_loss: 0.6380 - output_2_accuracy: 0.8434 - output_2_loss: 0.4369\n",
            "Epoch 372/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0609 - output_1_accuracy: 0.7666 - output_1_loss: 0.6242 - output_2_accuracy: 0.8418 - output_2_loss: 0.4367\n",
            "Epoch 373/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0752 - output_1_accuracy: 0.7633 - output_1_loss: 0.6352 - output_2_accuracy: 0.8446 - output_2_loss: 0.4400\n",
            "Epoch 374/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0578 - output_1_accuracy: 0.7685 - output_1_loss: 0.6210 - output_2_accuracy: 0.8446 - output_2_loss: 0.4367\n",
            "Epoch 375/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0693 - output_1_accuracy: 0.7691 - output_1_loss: 0.6215 - output_2_accuracy: 0.8431 - output_2_loss: 0.4478\n",
            "Epoch 376/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0749 - output_1_accuracy: 0.7636 - output_1_loss: 0.6415 - output_2_accuracy: 0.8497 - output_2_loss: 0.4334\n",
            "Epoch 377/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0572 - output_1_accuracy: 0.7629 - output_1_loss: 0.6209 - output_2_accuracy: 0.8458 - output_2_loss: 0.4363\n",
            "Epoch 378/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0468 - output_1_accuracy: 0.7743 - output_1_loss: 0.6120 - output_2_accuracy: 0.8458 - output_2_loss: 0.4348\n",
            "Epoch 379/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0514 - output_1_accuracy: 0.7720 - output_1_loss: 0.6124 - output_2_accuracy: 0.8456 - output_2_loss: 0.4391\n",
            "Epoch 380/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0633 - output_1_accuracy: 0.7662 - output_1_loss: 0.6266 - output_2_accuracy: 0.8422 - output_2_loss: 0.4368\n",
            "Epoch 381/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0496 - output_1_accuracy: 0.7720 - output_1_loss: 0.6199 - output_2_accuracy: 0.8471 - output_2_loss: 0.4297\n",
            "Epoch 382/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0593 - output_1_accuracy: 0.7630 - output_1_loss: 0.6262 - output_2_accuracy: 0.8460 - output_2_loss: 0.4330\n",
            "Epoch 383/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0474 - output_1_accuracy: 0.7682 - output_1_loss: 0.6155 - output_2_accuracy: 0.8426 - output_2_loss: 0.4319\n",
            "Epoch 384/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0554 - output_1_accuracy: 0.7717 - output_1_loss: 0.6214 - output_2_accuracy: 0.8457 - output_2_loss: 0.4340\n",
            "Epoch 385/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0723 - output_1_accuracy: 0.7657 - output_1_loss: 0.6231 - output_2_accuracy: 0.8413 - output_2_loss: 0.4492\n",
            "Epoch 386/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0609 - output_1_accuracy: 0.7668 - output_1_loss: 0.6308 - output_2_accuracy: 0.8461 - output_2_loss: 0.4300\n",
            "Epoch 387/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0609 - output_1_accuracy: 0.7630 - output_1_loss: 0.6329 - output_2_accuracy: 0.8483 - output_2_loss: 0.4280\n",
            "Epoch 388/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0507 - output_1_accuracy: 0.7711 - output_1_loss: 0.6120 - output_2_accuracy: 0.8456 - output_2_loss: 0.4387\n",
            "Epoch 389/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0659 - output_1_accuracy: 0.7694 - output_1_loss: 0.6325 - output_2_accuracy: 0.8443 - output_2_loss: 0.4334\n",
            "Epoch 390/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0712 - output_1_accuracy: 0.7621 - output_1_loss: 0.6335 - output_2_accuracy: 0.8426 - output_2_loss: 0.4377\n",
            "Epoch 391/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0618 - output_1_accuracy: 0.7649 - output_1_loss: 0.6322 - output_2_accuracy: 0.8479 - output_2_loss: 0.4296\n",
            "Epoch 392/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0705 - output_1_accuracy: 0.7611 - output_1_loss: 0.6389 - output_2_accuracy: 0.8486 - output_2_loss: 0.4317\n",
            "Epoch 393/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0435 - output_1_accuracy: 0.7734 - output_1_loss: 0.6182 - output_2_accuracy: 0.8494 - output_2_loss: 0.4253\n",
            "Epoch 394/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0632 - output_1_accuracy: 0.7674 - output_1_loss: 0.6278 - output_2_accuracy: 0.8428 - output_2_loss: 0.4354\n",
            "Epoch 395/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0553 - output_1_accuracy: 0.7654 - output_1_loss: 0.6253 - output_2_accuracy: 0.8458 - output_2_loss: 0.4300\n",
            "Epoch 396/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0669 - output_1_accuracy: 0.7693 - output_1_loss: 0.6308 - output_2_accuracy: 0.8432 - output_2_loss: 0.4361\n",
            "Epoch 397/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0456 - output_1_accuracy: 0.7679 - output_1_loss: 0.6250 - output_2_accuracy: 0.8476 - output_2_loss: 0.4206\n",
            "Epoch 398/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0529 - output_1_accuracy: 0.7641 - output_1_loss: 0.6230 - output_2_accuracy: 0.8491 - output_2_loss: 0.4299\n",
            "Epoch 399/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0524 - output_1_accuracy: 0.7713 - output_1_loss: 0.6195 - output_2_accuracy: 0.8481 - output_2_loss: 0.4329\n",
            "Epoch 400/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0549 - output_1_accuracy: 0.7700 - output_1_loss: 0.6191 - output_2_accuracy: 0.8425 - output_2_loss: 0.4358\n",
            "Epoch 401/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0652 - output_1_accuracy: 0.7667 - output_1_loss: 0.6322 - output_2_accuracy: 0.8451 - output_2_loss: 0.4330\n",
            "Epoch 402/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0390 - output_1_accuracy: 0.7754 - output_1_loss: 0.6101 - output_2_accuracy: 0.8480 - output_2_loss: 0.4288\n",
            "Epoch 403/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0438 - output_1_accuracy: 0.7687 - output_1_loss: 0.6251 - output_2_accuracy: 0.8548 - output_2_loss: 0.4187\n",
            "Epoch 404/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0481 - output_1_accuracy: 0.7687 - output_1_loss: 0.6214 - output_2_accuracy: 0.8479 - output_2_loss: 0.4266\n",
            "Epoch 405/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0472 - output_1_accuracy: 0.7697 - output_1_loss: 0.6261 - output_2_accuracy: 0.8494 - output_2_loss: 0.4211\n",
            "Epoch 406/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0467 - output_1_accuracy: 0.7653 - output_1_loss: 0.6222 - output_2_accuracy: 0.8492 - output_2_loss: 0.4245\n",
            "Epoch 407/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0487 - output_1_accuracy: 0.7710 - output_1_loss: 0.6176 - output_2_accuracy: 0.8458 - output_2_loss: 0.4312\n",
            "Epoch 408/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0471 - output_1_accuracy: 0.7723 - output_1_loss: 0.6166 - output_2_accuracy: 0.8493 - output_2_loss: 0.4305\n",
            "Epoch 409/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0373 - output_1_accuracy: 0.7657 - output_1_loss: 0.6263 - output_2_accuracy: 0.8540 - output_2_loss: 0.4110\n",
            "Epoch 410/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0437 - output_1_accuracy: 0.7732 - output_1_loss: 0.6148 - output_2_accuracy: 0.8466 - output_2_loss: 0.4289\n",
            "Epoch 411/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0609 - output_1_accuracy: 0.7689 - output_1_loss: 0.6280 - output_2_accuracy: 0.8497 - output_2_loss: 0.4329\n",
            "Epoch 412/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0402 - output_1_accuracy: 0.7722 - output_1_loss: 0.6115 - output_2_accuracy: 0.8491 - output_2_loss: 0.4287\n",
            "Epoch 413/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0627 - output_1_accuracy: 0.7659 - output_1_loss: 0.6305 - output_2_accuracy: 0.8475 - output_2_loss: 0.4322\n",
            "Epoch 414/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0569 - output_1_accuracy: 0.7658 - output_1_loss: 0.6237 - output_2_accuracy: 0.8459 - output_2_loss: 0.4332\n",
            "Epoch 415/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0579 - output_1_accuracy: 0.7658 - output_1_loss: 0.6276 - output_2_accuracy: 0.8471 - output_2_loss: 0.4303\n",
            "Epoch 416/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0515 - output_1_accuracy: 0.7664 - output_1_loss: 0.6177 - output_2_accuracy: 0.8487 - output_2_loss: 0.4338\n",
            "Epoch 417/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0630 - output_1_accuracy: 0.7705 - output_1_loss: 0.6257 - output_2_accuracy: 0.8426 - output_2_loss: 0.4373\n",
            "Epoch 418/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0545 - output_1_accuracy: 0.7712 - output_1_loss: 0.6214 - output_2_accuracy: 0.8476 - output_2_loss: 0.4331\n",
            "Epoch 419/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0340 - output_1_accuracy: 0.7742 - output_1_loss: 0.6132 - output_2_accuracy: 0.8442 - output_2_loss: 0.4207\n",
            "Epoch 420/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0483 - output_1_accuracy: 0.7698 - output_1_loss: 0.6080 - output_2_accuracy: 0.8443 - output_2_loss: 0.4402\n",
            "Epoch 421/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0333 - output_1_accuracy: 0.7766 - output_1_loss: 0.6056 - output_2_accuracy: 0.8511 - output_2_loss: 0.4277\n",
            "Epoch 422/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0531 - output_1_accuracy: 0.7657 - output_1_loss: 0.6252 - output_2_accuracy: 0.8491 - output_2_loss: 0.4280\n",
            "Epoch 423/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0431 - output_1_accuracy: 0.7690 - output_1_loss: 0.6196 - output_2_accuracy: 0.8501 - output_2_loss: 0.4235\n",
            "Epoch 424/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0591 - output_1_accuracy: 0.7672 - output_1_loss: 0.6265 - output_2_accuracy: 0.8458 - output_2_loss: 0.4326\n",
            "Epoch 425/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0313 - output_1_accuracy: 0.7753 - output_1_loss: 0.6050 - output_2_accuracy: 0.8538 - output_2_loss: 0.4263\n",
            "Epoch 426/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0379 - output_1_accuracy: 0.7711 - output_1_loss: 0.6154 - output_2_accuracy: 0.8505 - output_2_loss: 0.4225\n",
            "Epoch 427/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0501 - output_1_accuracy: 0.7669 - output_1_loss: 0.6223 - output_2_accuracy: 0.8471 - output_2_loss: 0.4278\n",
            "Epoch 428/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0368 - output_1_accuracy: 0.7733 - output_1_loss: 0.6167 - output_2_accuracy: 0.8512 - output_2_loss: 0.4202\n",
            "Epoch 429/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0634 - output_1_accuracy: 0.7679 - output_1_loss: 0.6248 - output_2_accuracy: 0.8438 - output_2_loss: 0.4387\n",
            "Epoch 430/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0305 - output_1_accuracy: 0.7745 - output_1_loss: 0.6125 - output_2_accuracy: 0.8545 - output_2_loss: 0.4180\n",
            "Epoch 431/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0327 - output_1_accuracy: 0.7699 - output_1_loss: 0.6151 - output_2_accuracy: 0.8515 - output_2_loss: 0.4176\n",
            "Epoch 432/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0501 - output_1_accuracy: 0.7718 - output_1_loss: 0.6202 - output_2_accuracy: 0.8464 - output_2_loss: 0.4299\n",
            "Epoch 433/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0343 - output_1_accuracy: 0.7706 - output_1_loss: 0.6113 - output_2_accuracy: 0.8509 - output_2_loss: 0.4231\n",
            "Epoch 434/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0195 - output_1_accuracy: 0.7757 - output_1_loss: 0.5943 - output_2_accuracy: 0.8475 - output_2_loss: 0.4252\n",
            "Epoch 435/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0407 - output_1_accuracy: 0.7696 - output_1_loss: 0.6127 - output_2_accuracy: 0.8470 - output_2_loss: 0.4280\n",
            "Epoch 436/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0376 - output_1_accuracy: 0.7723 - output_1_loss: 0.6163 - output_2_accuracy: 0.8519 - output_2_loss: 0.4213\n",
            "Epoch 437/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0409 - output_1_accuracy: 0.7747 - output_1_loss: 0.6039 - output_2_accuracy: 0.8451 - output_2_loss: 0.4370\n",
            "Epoch 438/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0652 - output_1_accuracy: 0.7593 - output_1_loss: 0.6414 - output_2_accuracy: 0.8492 - output_2_loss: 0.4237\n",
            "Epoch 439/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0196 - output_1_accuracy: 0.7793 - output_1_loss: 0.6011 - output_2_accuracy: 0.8540 - output_2_loss: 0.4185\n",
            "Epoch 440/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0267 - output_1_accuracy: 0.7721 - output_1_loss: 0.6033 - output_2_accuracy: 0.8477 - output_2_loss: 0.4234\n",
            "Epoch 441/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0353 - output_1_accuracy: 0.7740 - output_1_loss: 0.6167 - output_2_accuracy: 0.8543 - output_2_loss: 0.4187\n",
            "Epoch 442/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0406 - output_1_accuracy: 0.7741 - output_1_loss: 0.6102 - output_2_accuracy: 0.8458 - output_2_loss: 0.4304\n",
            "Epoch 443/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0284 - output_1_accuracy: 0.7732 - output_1_loss: 0.6080 - output_2_accuracy: 0.8540 - output_2_loss: 0.4204\n",
            "Epoch 444/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0504 - output_1_accuracy: 0.7724 - output_1_loss: 0.6124 - output_2_accuracy: 0.8454 - output_2_loss: 0.4381\n",
            "Epoch 445/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0421 - output_1_accuracy: 0.7751 - output_1_loss: 0.6121 - output_2_accuracy: 0.8462 - output_2_loss: 0.4300\n",
            "Epoch 446/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0331 - output_1_accuracy: 0.7801 - output_1_loss: 0.6048 - output_2_accuracy: 0.8520 - output_2_loss: 0.4283\n",
            "Epoch 447/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0464 - output_1_accuracy: 0.7754 - output_1_loss: 0.6165 - output_2_accuracy: 0.8505 - output_2_loss: 0.4299\n",
            "Epoch 448/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0738 - output_1_accuracy: 0.7604 - output_1_loss: 0.6427 - output_2_accuracy: 0.8480 - output_2_loss: 0.4311\n",
            "Epoch 449/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0305 - output_1_accuracy: 0.7729 - output_1_loss: 0.6114 - output_2_accuracy: 0.8500 - output_2_loss: 0.4191\n",
            "Epoch 450/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0427 - output_1_accuracy: 0.7731 - output_1_loss: 0.6135 - output_2_accuracy: 0.8475 - output_2_loss: 0.4292\n",
            "Epoch 451/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0325 - output_1_accuracy: 0.7726 - output_1_loss: 0.6178 - output_2_accuracy: 0.8530 - output_2_loss: 0.4147\n",
            "Epoch 452/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0099 - output_1_accuracy: 0.7773 - output_1_loss: 0.6018 - output_2_accuracy: 0.8552 - output_2_loss: 0.4082\n",
            "Epoch 453/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0221 - output_1_accuracy: 0.7757 - output_1_loss: 0.6046 - output_2_accuracy: 0.8541 - output_2_loss: 0.4175\n",
            "Epoch 454/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0406 - output_1_accuracy: 0.7736 - output_1_loss: 0.6136 - output_2_accuracy: 0.8482 - output_2_loss: 0.4270\n",
            "Epoch 455/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0324 - output_1_accuracy: 0.7776 - output_1_loss: 0.6045 - output_2_accuracy: 0.8478 - output_2_loss: 0.4279\n",
            "Epoch 456/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0322 - output_1_accuracy: 0.7721 - output_1_loss: 0.6074 - output_2_accuracy: 0.8484 - output_2_loss: 0.4248\n",
            "Epoch 457/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0533 - output_1_accuracy: 0.7659 - output_1_loss: 0.6237 - output_2_accuracy: 0.8483 - output_2_loss: 0.4296\n",
            "Epoch 458/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0219 - output_1_accuracy: 0.7744 - output_1_loss: 0.6096 - output_2_accuracy: 0.8567 - output_2_loss: 0.4123\n",
            "Epoch 459/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0421 - output_1_accuracy: 0.7743 - output_1_loss: 0.6108 - output_2_accuracy: 0.8498 - output_2_loss: 0.4313\n",
            "Epoch 460/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0492 - output_1_accuracy: 0.7723 - output_1_loss: 0.6168 - output_2_accuracy: 0.8459 - output_2_loss: 0.4324\n",
            "Epoch 461/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0476 - output_1_accuracy: 0.7715 - output_1_loss: 0.6232 - output_2_accuracy: 0.8487 - output_2_loss: 0.4244\n",
            "Epoch 462/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0500 - output_1_accuracy: 0.7734 - output_1_loss: 0.6132 - output_2_accuracy: 0.8471 - output_2_loss: 0.4367\n",
            "Epoch 463/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0253 - output_1_accuracy: 0.7751 - output_1_loss: 0.6055 - output_2_accuracy: 0.8502 - output_2_loss: 0.4198\n",
            "Epoch 464/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0580 - output_1_accuracy: 0.7717 - output_1_loss: 0.6244 - output_2_accuracy: 0.8445 - output_2_loss: 0.4336\n",
            "Epoch 465/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0198 - output_1_accuracy: 0.7737 - output_1_loss: 0.6067 - output_2_accuracy: 0.8523 - output_2_loss: 0.4130\n",
            "Epoch 466/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0372 - output_1_accuracy: 0.7671 - output_1_loss: 0.6250 - output_2_accuracy: 0.8532 - output_2_loss: 0.4122\n",
            "Epoch 467/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0358 - output_1_accuracy: 0.7761 - output_1_loss: 0.6114 - output_2_accuracy: 0.8507 - output_2_loss: 0.4244\n",
            "Epoch 468/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0209 - output_1_accuracy: 0.7747 - output_1_loss: 0.6102 - output_2_accuracy: 0.8541 - output_2_loss: 0.4107\n",
            "Epoch 469/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0394 - output_1_accuracy: 0.7689 - output_1_loss: 0.6207 - output_2_accuracy: 0.8503 - output_2_loss: 0.4187\n",
            "Epoch 470/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0395 - output_1_accuracy: 0.7751 - output_1_loss: 0.6092 - output_2_accuracy: 0.8492 - output_2_loss: 0.4303\n",
            "Epoch 471/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0533 - output_1_accuracy: 0.7724 - output_1_loss: 0.6128 - output_2_accuracy: 0.8452 - output_2_loss: 0.4405\n",
            "Epoch 472/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0412 - output_1_accuracy: 0.7676 - output_1_loss: 0.6216 - output_2_accuracy: 0.8483 - output_2_loss: 0.4196\n",
            "Epoch 473/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0266 - output_1_accuracy: 0.7743 - output_1_loss: 0.6088 - output_2_accuracy: 0.8494 - output_2_loss: 0.4178\n",
            "Epoch 474/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0396 - output_1_accuracy: 0.7720 - output_1_loss: 0.6147 - output_2_accuracy: 0.8530 - output_2_loss: 0.4249\n",
            "Epoch 475/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0582 - output_1_accuracy: 0.7689 - output_1_loss: 0.6208 - output_2_accuracy: 0.8469 - output_2_loss: 0.4374\n",
            "Epoch 476/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0240 - output_1_accuracy: 0.7725 - output_1_loss: 0.6150 - output_2_accuracy: 0.8555 - output_2_loss: 0.4090\n",
            "Epoch 477/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0369 - output_1_accuracy: 0.7677 - output_1_loss: 0.6256 - output_2_accuracy: 0.8527 - output_2_loss: 0.4113\n",
            "Epoch 478/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0360 - output_1_accuracy: 0.7754 - output_1_loss: 0.6139 - output_2_accuracy: 0.8542 - output_2_loss: 0.4221\n",
            "Epoch 479/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0442 - output_1_accuracy: 0.7683 - output_1_loss: 0.6142 - output_2_accuracy: 0.8460 - output_2_loss: 0.4300\n",
            "Epoch 480/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0389 - output_1_accuracy: 0.7722 - output_1_loss: 0.6155 - output_2_accuracy: 0.8455 - output_2_loss: 0.4234\n",
            "Epoch 481/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0326 - output_1_accuracy: 0.7736 - output_1_loss: 0.6180 - output_2_accuracy: 0.8537 - output_2_loss: 0.4146\n",
            "Epoch 482/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0354 - output_1_accuracy: 0.7715 - output_1_loss: 0.6200 - output_2_accuracy: 0.8548 - output_2_loss: 0.4155\n",
            "Epoch 483/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0246 - output_1_accuracy: 0.7768 - output_1_loss: 0.6094 - output_2_accuracy: 0.8518 - output_2_loss: 0.4151\n",
            "Epoch 484/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0469 - output_1_accuracy: 0.7685 - output_1_loss: 0.6174 - output_2_accuracy: 0.8471 - output_2_loss: 0.4295\n",
            "Epoch 485/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0224 - output_1_accuracy: 0.7768 - output_1_loss: 0.6044 - output_2_accuracy: 0.8522 - output_2_loss: 0.4180\n",
            "Epoch 486/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0382 - output_1_accuracy: 0.7720 - output_1_loss: 0.6079 - output_2_accuracy: 0.8455 - output_2_loss: 0.4303\n",
            "Epoch 487/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0397 - output_1_accuracy: 0.7735 - output_1_loss: 0.6131 - output_2_accuracy: 0.8515 - output_2_loss: 0.4266\n",
            "Epoch 488/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0266 - output_1_accuracy: 0.7744 - output_1_loss: 0.6054 - output_2_accuracy: 0.8513 - output_2_loss: 0.4212\n",
            "Epoch 489/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0262 - output_1_accuracy: 0.7734 - output_1_loss: 0.6036 - output_2_accuracy: 0.8517 - output_2_loss: 0.4226\n",
            "Epoch 490/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0420 - output_1_accuracy: 0.7702 - output_1_loss: 0.6110 - output_2_accuracy: 0.8473 - output_2_loss: 0.4310\n",
            "Epoch 491/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0211 - output_1_accuracy: 0.7760 - output_1_loss: 0.6016 - output_2_accuracy: 0.8522 - output_2_loss: 0.4195\n",
            "Epoch 492/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0131 - output_1_accuracy: 0.7805 - output_1_loss: 0.6003 - output_2_accuracy: 0.8536 - output_2_loss: 0.4128\n",
            "Epoch 493/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0389 - output_1_accuracy: 0.7695 - output_1_loss: 0.6134 - output_2_accuracy: 0.8526 - output_2_loss: 0.4255\n",
            "Epoch 494/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0377 - output_1_accuracy: 0.7711 - output_1_loss: 0.6185 - output_2_accuracy: 0.8525 - output_2_loss: 0.4191\n",
            "Epoch 495/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0190 - output_1_accuracy: 0.7759 - output_1_loss: 0.6035 - output_2_accuracy: 0.8503 - output_2_loss: 0.4155\n",
            "Epoch 496/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0188 - output_1_accuracy: 0.7758 - output_1_loss: 0.6091 - output_2_accuracy: 0.8520 - output_2_loss: 0.4097\n",
            "Epoch 497/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.9941 - output_1_accuracy: 0.7794 - output_1_loss: 0.5893 - output_2_accuracy: 0.8580 - output_2_loss: 0.4049\n",
            "Epoch 498/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0145 - output_1_accuracy: 0.7780 - output_1_loss: 0.5961 - output_2_accuracy: 0.8525 - output_2_loss: 0.4185\n",
            "Epoch 499/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0296 - output_1_accuracy: 0.7758 - output_1_loss: 0.6089 - output_2_accuracy: 0.8526 - output_2_loss: 0.4207\n",
            "Epoch 500/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0277 - output_1_accuracy: 0.7744 - output_1_loss: 0.6074 - output_2_accuracy: 0.8503 - output_2_loss: 0.4204\n",
            "Epoch 501/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0157 - output_1_accuracy: 0.7738 - output_1_loss: 0.6045 - output_2_accuracy: 0.8560 - output_2_loss: 0.4112\n",
            "Epoch 502/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0433 - output_1_accuracy: 0.7699 - output_1_loss: 0.6136 - output_2_accuracy: 0.8469 - output_2_loss: 0.4297\n",
            "Epoch 503/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0243 - output_1_accuracy: 0.7715 - output_1_loss: 0.6013 - output_2_accuracy: 0.8513 - output_2_loss: 0.4230\n",
            "Epoch 504/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0107 - output_1_accuracy: 0.7779 - output_1_loss: 0.5967 - output_2_accuracy: 0.8533 - output_2_loss: 0.4141\n",
            "Epoch 505/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0100 - output_1_accuracy: 0.7747 - output_1_loss: 0.6016 - output_2_accuracy: 0.8549 - output_2_loss: 0.4084\n",
            "Epoch 506/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0349 - output_1_accuracy: 0.7776 - output_1_loss: 0.6044 - output_2_accuracy: 0.8505 - output_2_loss: 0.4306\n",
            "Epoch 507/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0220 - output_1_accuracy: 0.7783 - output_1_loss: 0.6024 - output_2_accuracy: 0.8546 - output_2_loss: 0.4197\n",
            "Epoch 508/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0194 - output_1_accuracy: 0.7736 - output_1_loss: 0.6028 - output_2_accuracy: 0.8529 - output_2_loss: 0.4166\n",
            "Epoch 509/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0258 - output_1_accuracy: 0.7802 - output_1_loss: 0.6049 - output_2_accuracy: 0.8524 - output_2_loss: 0.4209\n",
            "Epoch 510/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0160 - output_1_accuracy: 0.7800 - output_1_loss: 0.5991 - output_2_accuracy: 0.8525 - output_2_loss: 0.4169\n",
            "Epoch 511/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0153 - output_1_accuracy: 0.7774 - output_1_loss: 0.5992 - output_2_accuracy: 0.8509 - output_2_loss: 0.4161\n",
            "Epoch 512/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0072 - output_1_accuracy: 0.7758 - output_1_loss: 0.6051 - output_2_accuracy: 0.8561 - output_2_loss: 0.4021\n",
            "Epoch 513/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0145 - output_1_accuracy: 0.7796 - output_1_loss: 0.5980 - output_2_accuracy: 0.8542 - output_2_loss: 0.4166\n",
            "Epoch 514/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0166 - output_1_accuracy: 0.7755 - output_1_loss: 0.6001 - output_2_accuracy: 0.8515 - output_2_loss: 0.4166\n",
            "Epoch 515/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0350 - output_1_accuracy: 0.7742 - output_1_loss: 0.6190 - output_2_accuracy: 0.8523 - output_2_loss: 0.4159\n",
            "Epoch 516/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0179 - output_1_accuracy: 0.7742 - output_1_loss: 0.6102 - output_2_accuracy: 0.8567 - output_2_loss: 0.4077\n",
            "Epoch 517/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0167 - output_1_accuracy: 0.7780 - output_1_loss: 0.6023 - output_2_accuracy: 0.8522 - output_2_loss: 0.4144\n",
            "Epoch 518/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0221 - output_1_accuracy: 0.7705 - output_1_loss: 0.6145 - output_2_accuracy: 0.8536 - output_2_loss: 0.4076\n",
            "Epoch 519/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0093 - output_1_accuracy: 0.7819 - output_1_loss: 0.5995 - output_2_accuracy: 0.8563 - output_2_loss: 0.4098\n",
            "Epoch 520/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0085 - output_1_accuracy: 0.7764 - output_1_loss: 0.6012 - output_2_accuracy: 0.8578 - output_2_loss: 0.4073\n",
            "Epoch 521/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0206 - output_1_accuracy: 0.7772 - output_1_loss: 0.6083 - output_2_accuracy: 0.8538 - output_2_loss: 0.4123\n",
            "Epoch 522/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0240 - output_1_accuracy: 0.7760 - output_1_loss: 0.6072 - output_2_accuracy: 0.8529 - output_2_loss: 0.4168\n",
            "Epoch 523/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0088 - output_1_accuracy: 0.7795 - output_1_loss: 0.5972 - output_2_accuracy: 0.8571 - output_2_loss: 0.4116\n",
            "Epoch 524/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0241 - output_1_accuracy: 0.7762 - output_1_loss: 0.6016 - output_2_accuracy: 0.8497 - output_2_loss: 0.4225\n",
            "Epoch 525/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0145 - output_1_accuracy: 0.7745 - output_1_loss: 0.6101 - output_2_accuracy: 0.8591 - output_2_loss: 0.4044\n",
            "Epoch 526/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0285 - output_1_accuracy: 0.7762 - output_1_loss: 0.5981 - output_2_accuracy: 0.8442 - output_2_loss: 0.4304\n",
            "Epoch 527/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9954 - output_1_accuracy: 0.7768 - output_1_loss: 0.5974 - output_2_accuracy: 0.8595 - output_2_loss: 0.3980\n",
            "Epoch 528/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0226 - output_1_accuracy: 0.7732 - output_1_loss: 0.6034 - output_2_accuracy: 0.8506 - output_2_loss: 0.4192\n",
            "Epoch 529/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0245 - output_1_accuracy: 0.7751 - output_1_loss: 0.6039 - output_2_accuracy: 0.8521 - output_2_loss: 0.4206\n",
            "Epoch 530/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0142 - output_1_accuracy: 0.7782 - output_1_loss: 0.6020 - output_2_accuracy: 0.8524 - output_2_loss: 0.4122\n",
            "Epoch 531/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0066 - output_1_accuracy: 0.7759 - output_1_loss: 0.5932 - output_2_accuracy: 0.8569 - output_2_loss: 0.4134\n",
            "Epoch 532/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0105 - output_1_accuracy: 0.7741 - output_1_loss: 0.6052 - output_2_accuracy: 0.8562 - output_2_loss: 0.4053\n",
            "Epoch 533/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0102 - output_1_accuracy: 0.7764 - output_1_loss: 0.6054 - output_2_accuracy: 0.8553 - output_2_loss: 0.4048\n",
            "Epoch 534/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0224 - output_1_accuracy: 0.7763 - output_1_loss: 0.6070 - output_2_accuracy: 0.8527 - output_2_loss: 0.4154\n",
            "Epoch 535/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0175 - output_1_accuracy: 0.7836 - output_1_loss: 0.6021 - output_2_accuracy: 0.8538 - output_2_loss: 0.4154\n",
            "Epoch 536/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0020 - output_1_accuracy: 0.7825 - output_1_loss: 0.5856 - output_2_accuracy: 0.8510 - output_2_loss: 0.4163\n",
            "Epoch 537/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9927 - output_1_accuracy: 0.7824 - output_1_loss: 0.5897 - output_2_accuracy: 0.8564 - output_2_loss: 0.4031\n",
            "Epoch 538/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0068 - output_1_accuracy: 0.7783 - output_1_loss: 0.5952 - output_2_accuracy: 0.8553 - output_2_loss: 0.4116\n",
            "Epoch 539/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0235 - output_1_accuracy: 0.7756 - output_1_loss: 0.6126 - output_2_accuracy: 0.8539 - output_2_loss: 0.4110\n",
            "Epoch 540/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0035 - output_1_accuracy: 0.7748 - output_1_loss: 0.6021 - output_2_accuracy: 0.8549 - output_2_loss: 0.4013\n",
            "Epoch 541/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0011 - output_1_accuracy: 0.7825 - output_1_loss: 0.5874 - output_2_accuracy: 0.8501 - output_2_loss: 0.4137\n",
            "Epoch 542/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0165 - output_1_accuracy: 0.7751 - output_1_loss: 0.5972 - output_2_accuracy: 0.8474 - output_2_loss: 0.4193\n",
            "Epoch 543/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0149 - output_1_accuracy: 0.7793 - output_1_loss: 0.5914 - output_2_accuracy: 0.8514 - output_2_loss: 0.4234\n",
            "Epoch 544/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0109 - output_1_accuracy: 0.7767 - output_1_loss: 0.5996 - output_2_accuracy: 0.8536 - output_2_loss: 0.4113\n",
            "Epoch 545/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0037 - output_1_accuracy: 0.7727 - output_1_loss: 0.6073 - output_2_accuracy: 0.8591 - output_2_loss: 0.3965\n",
            "Epoch 546/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0072 - output_1_accuracy: 0.7755 - output_1_loss: 0.5994 - output_2_accuracy: 0.8559 - output_2_loss: 0.4079\n",
            "Epoch 547/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0143 - output_1_accuracy: 0.7751 - output_1_loss: 0.6025 - output_2_accuracy: 0.8541 - output_2_loss: 0.4119\n",
            "Epoch 548/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0090 - output_1_accuracy: 0.7815 - output_1_loss: 0.5952 - output_2_accuracy: 0.8523 - output_2_loss: 0.4139\n",
            "Epoch 549/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9984 - output_1_accuracy: 0.7798 - output_1_loss: 0.5933 - output_2_accuracy: 0.8532 - output_2_loss: 0.4050\n",
            "Epoch 550/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9792 - output_1_accuracy: 0.7796 - output_1_loss: 0.5876 - output_2_accuracy: 0.8626 - output_2_loss: 0.3916\n",
            "Epoch 551/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0126 - output_1_accuracy: 0.7756 - output_1_loss: 0.6054 - output_2_accuracy: 0.8547 - output_2_loss: 0.4072\n",
            "Epoch 552/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0204 - output_1_accuracy: 0.7782 - output_1_loss: 0.5960 - output_2_accuracy: 0.8516 - output_2_loss: 0.4244\n",
            "Epoch 553/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9978 - output_1_accuracy: 0.7781 - output_1_loss: 0.5944 - output_2_accuracy: 0.8572 - output_2_loss: 0.4034\n",
            "Epoch 554/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0007 - output_1_accuracy: 0.7812 - output_1_loss: 0.5943 - output_2_accuracy: 0.8555 - output_2_loss: 0.4065\n",
            "Epoch 555/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0049 - output_1_accuracy: 0.7770 - output_1_loss: 0.5961 - output_2_accuracy: 0.8570 - output_2_loss: 0.4087\n",
            "Epoch 556/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9972 - output_1_accuracy: 0.7723 - output_1_loss: 0.5987 - output_2_accuracy: 0.8550 - output_2_loss: 0.3984\n",
            "Epoch 557/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0151 - output_1_accuracy: 0.7797 - output_1_loss: 0.5904 - output_2_accuracy: 0.8526 - output_2_loss: 0.4246\n",
            "Epoch 558/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0237 - output_1_accuracy: 0.7752 - output_1_loss: 0.6087 - output_2_accuracy: 0.8562 - output_2_loss: 0.4150\n",
            "Epoch 559/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9948 - output_1_accuracy: 0.7821 - output_1_loss: 0.5897 - output_2_accuracy: 0.8555 - output_2_loss: 0.4052\n",
            "Epoch 560/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0184 - output_1_accuracy: 0.7752 - output_1_loss: 0.6067 - output_2_accuracy: 0.8538 - output_2_loss: 0.4117\n",
            "Epoch 561/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0195 - output_1_accuracy: 0.7782 - output_1_loss: 0.6048 - output_2_accuracy: 0.8565 - output_2_loss: 0.4147\n",
            "Epoch 562/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9988 - output_1_accuracy: 0.7820 - output_1_loss: 0.5914 - output_2_accuracy: 0.8566 - output_2_loss: 0.4073\n",
            "Epoch 563/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9970 - output_1_accuracy: 0.7834 - output_1_loss: 0.5877 - output_2_accuracy: 0.8568 - output_2_loss: 0.4093\n",
            "Epoch 564/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0012 - output_1_accuracy: 0.7784 - output_1_loss: 0.5955 - output_2_accuracy: 0.8552 - output_2_loss: 0.4057\n",
            "Epoch 565/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0188 - output_1_accuracy: 0.7798 - output_1_loss: 0.5929 - output_2_accuracy: 0.8504 - output_2_loss: 0.4259\n",
            "Epoch 566/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0136 - output_1_accuracy: 0.7768 - output_1_loss: 0.6029 - output_2_accuracy: 0.8547 - output_2_loss: 0.4107\n",
            "Epoch 567/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0178 - output_1_accuracy: 0.7778 - output_1_loss: 0.5991 - output_2_accuracy: 0.8500 - output_2_loss: 0.4187\n",
            "Epoch 568/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0235 - output_1_accuracy: 0.7666 - output_1_loss: 0.6194 - output_2_accuracy: 0.8544 - output_2_loss: 0.4041\n",
            "Epoch 569/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9934 - output_1_accuracy: 0.7796 - output_1_loss: 0.5892 - output_2_accuracy: 0.8558 - output_2_loss: 0.4042\n",
            "Epoch 570/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0228 - output_1_accuracy: 0.7808 - output_1_loss: 0.6064 - output_2_accuracy: 0.8537 - output_2_loss: 0.4163\n",
            "Epoch 571/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0050 - output_1_accuracy: 0.7744 - output_1_loss: 0.5990 - output_2_accuracy: 0.8551 - output_2_loss: 0.4060\n",
            "Epoch 572/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.9765 - output_1_accuracy: 0.7843 - output_1_loss: 0.5793 - output_2_accuracy: 0.8623 - output_2_loss: 0.3972\n",
            "Epoch 573/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9972 - output_1_accuracy: 0.7832 - output_1_loss: 0.5885 - output_2_accuracy: 0.8572 - output_2_loss: 0.4087\n",
            "Epoch 574/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0140 - output_1_accuracy: 0.7822 - output_1_loss: 0.5950 - output_2_accuracy: 0.8550 - output_2_loss: 0.4190\n",
            "Epoch 575/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0030 - output_1_accuracy: 0.7787 - output_1_loss: 0.5953 - output_2_accuracy: 0.8575 - output_2_loss: 0.4077\n",
            "Epoch 576/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9923 - output_1_accuracy: 0.7839 - output_1_loss: 0.5902 - output_2_accuracy: 0.8543 - output_2_loss: 0.4021\n",
            "Epoch 577/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0045 - output_1_accuracy: 0.7822 - output_1_loss: 0.5930 - output_2_accuracy: 0.8528 - output_2_loss: 0.4115\n",
            "Epoch 578/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0002 - output_1_accuracy: 0.7856 - output_1_loss: 0.5872 - output_2_accuracy: 0.8556 - output_2_loss: 0.4130\n",
            "Epoch 579/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0162 - output_1_accuracy: 0.7795 - output_1_loss: 0.5931 - output_2_accuracy: 0.8520 - output_2_loss: 0.4231\n",
            "Epoch 580/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.9951 - output_1_accuracy: 0.7832 - output_1_loss: 0.5932 - output_2_accuracy: 0.8580 - output_2_loss: 0.4019\n",
            "Epoch 581/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0062 - output_1_accuracy: 0.7816 - output_1_loss: 0.5936 - output_2_accuracy: 0.8530 - output_2_loss: 0.4126\n",
            "Epoch 582/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0054 - output_1_accuracy: 0.7805 - output_1_loss: 0.5926 - output_2_accuracy: 0.8498 - output_2_loss: 0.4129\n",
            "Epoch 583/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0107 - output_1_accuracy: 0.7787 - output_1_loss: 0.6025 - output_2_accuracy: 0.8521 - output_2_loss: 0.4082\n",
            "Epoch 584/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0087 - output_1_accuracy: 0.7824 - output_1_loss: 0.5937 - output_2_accuracy: 0.8534 - output_2_loss: 0.4150\n",
            "Epoch 585/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0186 - output_1_accuracy: 0.7739 - output_1_loss: 0.6090 - output_2_accuracy: 0.8548 - output_2_loss: 0.4096\n",
            "Epoch 586/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 1.0010 - output_1_accuracy: 0.7865 - output_1_loss: 0.5827 - output_2_accuracy: 0.8532 - output_2_loss: 0.4183\n",
            "Epoch 587/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9913 - output_1_accuracy: 0.7791 - output_1_loss: 0.5948 - output_2_accuracy: 0.8621 - output_2_loss: 0.3965\n",
            "Epoch 588/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9949 - output_1_accuracy: 0.7847 - output_1_loss: 0.5857 - output_2_accuracy: 0.8552 - output_2_loss: 0.4092\n",
            "Epoch 589/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9993 - output_1_accuracy: 0.7754 - output_1_loss: 0.5990 - output_2_accuracy: 0.8555 - output_2_loss: 0.4004\n",
            "Epoch 590/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0098 - output_1_accuracy: 0.7807 - output_1_loss: 0.5890 - output_2_accuracy: 0.8543 - output_2_loss: 0.4209\n",
            "Epoch 591/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0286 - output_1_accuracy: 0.7735 - output_1_loss: 0.6090 - output_2_accuracy: 0.8553 - output_2_loss: 0.4196\n",
            "Epoch 592/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9938 - output_1_accuracy: 0.7857 - output_1_loss: 0.5890 - output_2_accuracy: 0.8588 - output_2_loss: 0.4048\n",
            "Epoch 593/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9979 - output_1_accuracy: 0.7846 - output_1_loss: 0.5920 - output_2_accuracy: 0.8568 - output_2_loss: 0.4059\n",
            "Epoch 594/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0192 - output_1_accuracy: 0.7745 - output_1_loss: 0.6081 - output_2_accuracy: 0.8568 - output_2_loss: 0.4111\n",
            "Epoch 595/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9972 - output_1_accuracy: 0.7795 - output_1_loss: 0.5940 - output_2_accuracy: 0.8611 - output_2_loss: 0.4032\n",
            "Epoch 596/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0175 - output_1_accuracy: 0.7785 - output_1_loss: 0.6051 - output_2_accuracy: 0.8533 - output_2_loss: 0.4124\n",
            "Epoch 597/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.9993 - output_1_accuracy: 0.7818 - output_1_loss: 0.5895 - output_2_accuracy: 0.8564 - output_2_loss: 0.4098\n",
            "Epoch 598/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 1.0069 - output_1_accuracy: 0.7803 - output_1_loss: 0.6000 - output_2_accuracy: 0.8570 - output_2_loss: 0.4069\n",
            "Epoch 599/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0039 - output_1_accuracy: 0.7842 - output_1_loss: 0.5900 - output_2_accuracy: 0.8524 - output_2_loss: 0.4139\n",
            "Epoch 600/600\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.0093 - output_1_accuracy: 0.7816 - output_1_loss: 0.5950 - output_2_accuracy: 0.8545 - output_2_loss: 0.4143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7961602e4e20>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione"
      ],
      "metadata": {
        "id": "l5lzBotwL5QN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo innanzi tutto il generatore di testing."
      ],
      "metadata": {
        "id": "9_p4UuG1QF8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
        "\n",
        "eval_samples_x, eval_samples_y = next(testgen)\n",
        "print(eval_samples_x.shape)\n",
        "print(eval_samples_y[0].shape)"
      ],
      "metadata": {
        "id": "1GllTEtPN_xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe7ad9e-7c88-4ae5-c326-1fefe08e84e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(10000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "    eval_samples_x, eval_samples_y = next(testgen)\n",
        "    guesses = model(eval_samples_x)\n",
        "\n",
        "    output_1_guesses = guesses[0]\n",
        "    output_2_guesses = guesses[1]\n",
        "\n",
        "    correct_guesses_1 = np.argmax(output_1_guesses, axis=1) == np.argmax(eval_samples_y[0], axis=1)\n",
        "    correct_guesses_2 = np.argmax(output_2_guesses, axis=1) == np.argmax(eval_samples_y[1], axis=1)\n",
        "\n",
        "    return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2"
      ],
      "metadata": {
        "id": "gomFTuuDOy8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4AL2M6yjJno",
        "outputId": "4bfc2a1a-625a-4eb0-8033-b330a0913c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.80785"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let us repeat the evaluation ten times, and compute the standard deviation"
      ],
      "metadata": {
        "id": "7usBI88dje70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "for i in range(repeat_eval):\n",
        "  eval_results.append(eval_model(model))\n",
        "print(\"mean accuracy = \", np.mean(eval_results))\n",
        "print(\"standard deviation = \", np.std(eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFu8iEt9jdZA",
        "outputId": "23ee91f6-01f8-42e3-9a1e-95dd1277632f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy =  0.8056000000000001\n",
            "standard deviation =  0.0020624015128000734\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}